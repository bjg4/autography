---
title: "Falsely Blaming Yourself"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 15
scraped_date: '2026-01-19'
---

**Falsely Blaming Yourself**


I have studied people making errors—sometimes serious ones—
with mechanical devices, light switches and fuses, computer operating systems and word processors, even airplanes and nuclear
power plants. Invariably people feel guilty and either try to hide
the error or blame themselves for “stupidity” or “clumsiness.” I
often have difficulty getting permission to watch: nobody likes to
be observed performing badly. I point out that the design is faulty
and that others make the same errors, yet if the task appears simple or trivial, people still blame themselves. It is almost as if they
take perverse pride in thinking of themselves as mechanically
incompetent.
I once was asked by a large computer company to evaluate a
brand-new product. I spent a day learning to use it and trying
it out on various problems. In using the keyboard to enter data, it
was necessary to differentiate between the Return key and the Enter key. If the wrong key was pressed, the last few minutes’ work
was irrevocably lost.
I pointed out this problem to the designer, explaining that I,
myself, had made the error frequently and that my analyses indicated that this was very likely to be a frequent error among users.
The designer’s first response was: “Why did you make that error?
Didn’t you read the manual?” He proceeded to explain the different functions of the two keys.


two: _The Psychology of Everyday Actions_ **65**


“Yes, yes,” I explained, “I understand the two keys, I simply confuse
them. They have similar functions, are located in similar locations on
the keyboard, and as a skilled typist, I often hit Return automatically,
without thought. Certainly others have had similar problems.”
“Nope,” said the designer. He claimed that I was the only person who had ever complained, and the company’s employees had
been using the system for many months. I was skeptical, so we
went together to some of the employees and asked them whether
they had ever hit the Return key when they should have hit Enter.
And did they ever lose their work as a result?
“Oh, yes,” they said, “we do that a lot.”
Well, how come nobody ever said anything about it? After all,
they were encouraged to report all problems with the system. The
reason was simple: when the system stopped working or did something strange, they dutifully reported it as a problem. But when
they made the Return versus Enter error, they blamed themselves.
After all, they had been told what to do. They had simply erred.
The idea that a person is at fault when something goes wrong is
deeply entrenched in society. That’s why we blame others and even
ourselves. Unfortunately, the idea that a person is at fault is imbedded in the legal system. When major accidents occur, official courts
of inquiry are set up to assess the blame. More and more often the
blame is attributed to “human error.” The person involved can
be fined, punished, or fired. Maybe training procedures are revised.
The law rests comfortably. But in my experience, human error usually
is a result of poor design: it should be called system error. Humans
err continually; it is an intrinsic part of our nature. System design
should take this into account. Pinning the blame on the person may
be a comfortable way to proceed, but why was the system ever designed so that a single act by a single person could cause calamity?
Worse, blaming the person without fixing the root, underlying cause
does not fix the problem: the same error is likely to be repeated by
someone else. I return to the topic of human error in Chapter 5.
Of course, people do make errors. Complex devices will always
require some instruction, and someone using them without instruction should expect to make errors and to be confused. But


**66** _The Design of Everyday Things_


designers should take special pains to make errors as cost-free as
possible. Here is my credo about errors:


Eliminate the term _human error_ . Instead, talk about communication and interaction: what we call an error is usually bad communication or interaction. When people collaborate with one another, the word error is never used to characterize another person’s
utterance. That’s because each person is trying to understand
and respond to the other, and when something is not understood
or seems inappropriate, it is questioned, clarified, and the collaboration continues. Why can’t the interaction between a person
and a machine be thought of as collaboration?
Machines are not people. They can’t communicate and understand the same way we do. This means that their designers have
a special obligation to ensure that the behavior of machines is understandable to the people who interact with them. True collaboration requires each party to make some effort to accommodate
and understand the other. When we collaborate with machines, it
is people who must do all the accommodation. Why shouldn’t the
machine be more friendly? The machine should accept normal human behavior, but just as people often subconsciously assess the
accuracy of things being said, machines should judge the quality of
information given it, in this case to help its operators avoid grievous errors because of simple slips (discussed in Chapter 5). Today,
we insist that people perform abnormally, to adapt themselves to
the peculiar demands of machines, which includes always giving
precise, accurate information. Humans are particularly bad at this,
yet when they fail to meet the arbitrary, inhuman requirements of
machines, we call it human error. No, it is design error.
Designers should strive to minimize the chance of inappropriate actions in the first place by using affordances, signifiers,
good mapping, and constraints to guide the actions. If a person
performs an inappropriate action, the design should maximize
the chance that this can be discovered and then rectified. This

requires good, intelligible feedback coupled with a simple, clear
conceptual model. When people understand what has happened,
what state the system is in, and what the most appropriate set of
actions is, they can perform their activities more effectively.


two: _The Psychology of Everyday Actions_ **67**


People are not machines. Machines don’t have to deal with
continual interruptions. People are subjected to continual interruptions. As a result, we are often bouncing back and forth between tasks, having to recover our place, what we were doing,
and what we were thinking when we return to a previous task.
No wonder we sometimes forget our place when we return to the
original task, either skipping or repeating a step, or imprecisely
retaining the information we were about to enter.
Our strengths are in our flexibility and creativity, in coming up
with solutions to novel problems. We are creative and imaginative,
not mechanical and precise. Machines require precision and accuracy; people don’t. And we are particularly bad at providing precise
and accurate inputs. So why are we always required to do so? Why
do we put the requirements of machines above those of people?
When people interact with machines, things will not always
go smoothly. This is to be expected. So designers should anticipate this. It is easy to design devices that work well when everything goes as planned. The hard and necessary part of design is to
make things work well even when things do not go as planned.


**HOW TECHNOLOGY CAN ACCOMMODATE HUMAN BEHAVIOR**


In the past, cost prevented many manufacturers from providing
useful feedback that would assist people in forming accurate
conceptual models. The cost of color displays large and flexible
enough to provide the required information was prohibitive for
small, inexpensive devices. But as the cost of sensors and displays
has dropped, it is now possible to do a lot more.
Thanks to display screens, telephones are much easier to use than
ever before, so my extensive criticisms of phones found in the earlier
edition of this book have been removed. I look forward to great improvements in all our devices now that the importance of these design principles are becoming recognized and the enhanced quality
and lower costs of displays make it possible to implement the ideas.


**PROV IDING A CONC EP T UAL MODEL FOR A HOME T HER MOSTAT**


My thermostat, for example (designed by Nest Labs), has a colorful
display that is normally off, turning on only when it senses that I


**68** _The Design of Everyday Things_


**FIGURE 2.6.** **A Thermostat with an Explicit Concep-**
**tual Model.** This thermostat, manufactured by Nest Labs,
helps people form a good conceptual model of its operation. Photo A shows the thermostat. The background, blue,
indicates that it is now cooling the home. The current temperature is 75°F (24°C) and the target temperature is 72°F
(22°C), which it expects to reach in 20 minutes. Photo B
shows its use of a smart phone to deliver a summary of its
settings and the home’s energy use. Both A and B combine
to help the home dweller develop conceptual models of
the thermostat and the home’s energy consumption. (Photographs courtesy of Nest Labs, Inc.)


**B.**





am nearby. Then it provides me with the current temperature of
the room, the temperature to which it is set, and whether it is heating or cooling the room (the background color changes from black
when it is neither heating nor cooling, to orange while heating, or
to blue while cooling). It learns my daily patterns, so it changes
temperature automatically, lowering it at bedtime, raising it again
in the morning, and going into “away” mode when it detects that
nobody is in the house. All the time, it explains what it is doing.
Thus, when it has to change the room temperature substantially
(either because someone has entered a manual change or because
it has decided that it is now time to switch), it gives a prediction:
“Now 75°, will be 72° in 20 minutes.” In addition, Nest can be connected wirelessly to smart devices that allow for remote operation
of the thermostat and also for larger screens to provide a detailed
analysis of its performance, aiding the home occupant’s development of a conceptual model both of Nest and also of the home’s energy consumption. Is Nest perfect? No, but it marks improvement
in the collaborative interaction of people and everyday things.


two: _The Psychology of Everyday Actions_ **69**


**EN T ER ING DAT ES, T IMES, A ND T ELEPHONE N U MBERS**


Many machines are programmed to be very fussy about the form
of input they require, where the fussiness is not a requirement of
the machine but due to the lack of consideration for people in the
design of the software. In other words: inappropriate programming. Consider these examples.
Many of us spend hours filling out forms on computers—forms
that require names, dates, addresses, telephone numbers, monetary sums, and other information in a fixed, rigid format. Worse,
often we are not even told the correct format until we get it wrong.
Why not figure out the variety of ways a person might fill out a
form and accommodate all of them? Some companies have done
excellent jobs at this, so let us celebrate their actions.
Consider Microsoft’s calendar program. Here, it is possible to
specify dates any way you like: “November 23, 2015,” “23 Nov.
15,” or “11.23.15.” It even accepts phrases such as “a week from
Thursday,” “tomorrow,” “a week from tomorrow,” or “yesterday.”
Same with time. You can enter the time any way you want: “3:45
PM,” “15.35,” “an hour,” “two and one-half hours.” Same with
telephone numbers: Want to start with a + sign (to indicate the code
for international dialing)? No problem. Like to separate the number fields with spaces, dashes, parentheses, slashes, periods? No
problem. As long as the program can decipher the date, time, or
telephone number into a legal format, it is accepted. I hope the
team that worked on this got bonuses and promotions.
Although I single out Microsoft for being the pioneer in accepting a wide variety of formats, it is now becoming standard practice. By the time you read this, I would hope that every program
would permit any intelligible format for names, dates, phone numbers, street addresses, and so on, transforming whatever is entered
into whatever form the internal programming needs. But I predict
that even in the twenty-second century, there will still be forms
that require precise accurate (but arbitrary) formats for no reason
except the laziness of the programming team. Perhaps in the years
that pass between this book’s publication and when you are read

**70** _The Design of Everyday Things_


ing this, great improvements will have been made. If we are all
lucky, this section will be badly out of date. I hope so.


**The Seven Stages of Action:**
**Seven Fundamental Design Principles**


The seven-stage model of the action cycle can be a valuable design tool, for it provides a basic checklist of questions to ask. In
general, each stage of action requires its own special design strategies and, in turn, provides its own opportunity for disaster. Figure
2.7 summarizes the questions:


1. What do I want to accomplish?
2. What are the alternative action sequences?

3. What action can I do now?

4. How do I do it?

5. What happened?

6. What does it mean?

7. Is this okay? Have I accomplished my goal?


Anyone using a product should always be able to determine the
answers to all seven questions. This puts the burden on the designer


**F IGU R E 2 .7.** **The Seven**
**Stages of Action as Design**
**Aids.** Each of the seven stages
indicates a place where the
person using the system has a
question. The seven questions
pose seven design themes.
How should the design convey the information required
to answer the user’s question?
Through appropriate constraint and mappings, signifiers and conceptual models,
feedback and visibility. The
information that helps answer
questions of execution (doing)
is _feedforward._ The information
that aids in understanding
what has happened is _feedback._


two: _The Psychology of Everyday Actions_ **71**


to ensure that at each stage, the product provides the information
required to answer the question.
The information that helps answer questions of execution (doing) is _feedforward._ The information that aids in understanding
what has happened is _feedback._ Everyone knows what feedback is.
It helps you know what happened. But how do you know what
you can do? That’s the role of feedforward, a term borrowed from
control theory.
Feedforward is accomplished through appropriate use of signifiers, constraints, and mappings. The conceptual model plays an
important role. Feedback is accomplished through explicit information about the impact of the action. Once again, the conceptual
model plays an important role.
Both feedback and feedforward need to be presented in a form that
is readily interpreted by the people using the system. The presentation has to match how people view the goal they are trying to achieve
and their expectations. Information must match human needs.
The insights from the seven stages of action lead us to seven fundamental principles of design:


1. **Discoverability.** It is possible to determine what actions are possible

and the current state of the device.

2. **Feedback.** There is full and continuous information about the results

of actions and the current state of the product or service. After an
action has been executed, it is easy to determine the new state.
3. **Conceptual model.** The design projects all the information needed
to create a good conceptual model of the system, leading to understanding and a feeling of control. The conceptual model enhances
both discoverability and evaluation of results.
4. **Affordances.** The proper affordances exist to make the desired actions possible.
5. **Signifiers.** Effective use of signifiers ensures discoverability and that
the feedback is well communicated and intelligible.
6. **Mappings.** The relationship between controls and their actions follows the principles of good mapping, enhanced as much as possible
through spatial layout and temporal contiguity.


**72** _The Design of Everyday Things_


7. **Constraints.** Providing physical, logical, semantic, and cultural constraints guides actions and eases interpretation.


The next time you can’t immediately figure out the shower control in a hotel room or have trouble using an unfamiliar television
set or kitchen appliance, remember that the problem is in the design. Ask yourself where the problem lies. At which of the seven
stages of action does it fail? Which design principles are deficient?
But it is easy to find fault: the key is to be able to do things
better. Ask yourself how the difficulty came about. Realize that
many different groups of people might have been involved, each
of which might have had intelligent, sensible reasons for their actions. For example, a troublesome bathroom shower was designed
by people who were unable to know how it would be installed,
then the shower controls might have been selected by a building
contractor to fit the home plans provided by yet another person.
Finally, a plumber, who may not have had contact with any of the
other people, did the installation. Where did the problems arise? It
could have been at any one (or several) of these stages. The result
may appear to be poor design, but it may actually arise from poor

communication.

One of my self-imposed rules is, “Don’t criticize unless you can
do better.” Try to understand how the faulty design might have
occurred: try to determine how it could have been done otherwise.
Thinking about the causes and possible fixes to bad design should
make you better appreciate good design. So, the next time you
come across a well-designed object, one that you can use smoothly
and effortlessly on the first try, stop and examine it. Consider how
well it masters the seven stages of action and the principles of design. Recognize that most of our interactions with products are actually interactions with a complex system: good design requires
consideration of the entire system to ensure that the requirements,
intentions, and desires at each stage are faithfully understood and
respected at all the other stages.


two: _The Psychology of Everyday Actions_ **73**


**C H A P T E R T H R E E**


**C h a p t e r T h r e e**