---
title: "The Complexity of Modern Devices"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 3
scraped_date: '2026-01-19'
---

**The Complexity of Modern Devices**


All artificial things are designed. Whether it is the layout of furniture in a room, the paths through a garden or forest, or the intricacies of an electronic device, some person or group of people
had to decide upon the layout, operation, and mechanisms. Not
all designed things involve physical structures. Services, lectures,
rules and procedures, and the organizational structures of businesses and governments do not have physical mechanisms, but
their rules of operation have to be designed, sometimes informally,
sometimes precisely recorded and specified.
But even though people have designed things since prehistoric
times, the field of design is relatively new, divided into many areas
of specialty. Because everything is designed, the number of areas is
enormous, ranging from clothes and furniture to complex control
rooms and bridges. This book covers everyday things, focusing on
the interplay between technology and people to ensure that the
products actually fulfill human needs while being understandable and usable. In the best of cases, the products should also be
delightful and enjoyable, which means that not only must the requirements of engineering, manufacturing, and ergonomics be satisfied, but attention must be paid to the entire experience, which
means the aesthetics of form and the quality of interaction. The
major areas of design relevant to this book are industrial design,
interaction design, and experience design. None of the fields is
well defined, but the focus of the efforts does vary, with industrial


**4** _The Design of Everyday Things_


designers emphasizing form and material, interactive designers
emphasizing understandability and usability, and experience designers emphasizing the emotional impact. Thus:


**Industrial design:** The professional service of creating and developing
concepts and specifications that optimize the function, value, and
appearance of products and systems for the mutual benefit of both
user and manufacturer (from the _Industrial Design Society of America’s_

website).

**Interaction design:** The focus is upon how people interact with technology. The goal is to enhance people’s understanding of what can be
done, what is happening, and what has just occurred. Interaction design draws upon principles of psychology, design, art, and emotion
to ensure a positive, enjoyable experience.
**Experience design:** The practice of designing products, processes, services, events, and environments with a focus placed on the quality
and enjoyment of the total experience.


Design is concerned with how things work, how they are controlled, and the nature of the interaction between people and
technology. When done well, the results are brilliant, pleasurable
products. When done badly, the products are unusable, leading to
great frustration and irritation. Or they might be usable, but force
us to behave the way the product wishes rather than as we wish.
Machines, after all, are conceived, designed, and constructed by
people. By human standards, machines are pretty limited. They
do not maintain the same kind of rich history of experiences that
people have in common with one another, experiences that enable
us to interact with others because of this shared understanding.
Instead, machines usually follow rather simple, rigid rules of behavior. If we get the rules wrong even slightly, the machine does
what it is told, no matter how insensible and illogical. People are
imaginative and creative, filled with common sense; that is, a lot of
valuable knowledge built up over years of experience. But instead
of capitalizing on these strengths, machines require us to be precise
and accurate, things we are not very good at. Machines have no


one: _The Psychopathology of Everyday Things_ **5**


leeway or common sense. Moreover, many of the rules followed
by a machine are known only by the machine and its designers.
When people fail to follow these bizarre, secret rules, and the
machine does the wrong thing, its operators are blamed for not
understanding the machine, for not following its rigid specifications. With everyday objects, the result is frustration. With complex
devices and commercial and industrial processes, the resulting
difficulties can lead to accidents, injuries, and even deaths. It is
time to reverse the situation: to cast the blame upon the machines
and their design. It is the machine and its design that are at fault. It
is the duty of machines and those who design them to understand
people. It is not our duty to understand the arbitrary, meaningless
dictates of machines.

The reasons for the deficiencies in human-machine interaction

are numerous. Some come from the limitations of today’s technology. Some come from self-imposed restrictions by the designers,
often to hold down cost. But most of the problems come from a
complete lack of understanding of the design principles necessary
for effective human-machine interaction. Why this deficiency? Because much of the design is done by engineers who are experts
in technology but limited in their understanding of people. “We
are people ourselves,” they think, “so we understand people.” But
in fact, we humans are amazingly complex. Those who have not
studied human behavior often think it is pretty simple. Engineers,
moreover, make the mistake of thinking that logical explanation is
sufficient: “If only people would read the instructions,” they say,
“everything would be all right.”
Engineers are trained to think logically. As a result, they come to
believe that all people must think this way, and they design their
machines accordingly. When people have trouble, the engineers
are upset, but often for the wrong reason. “What are these people
doing?” they will wonder. “Why are they doing that?” The problem with the designs of most engineers is that they are too logical.
We have to accept human behavior the way it is, not the way we
would wish it to be.


**6** _The Design of Everyday Things_


I used to be an engineer, focused upon technical requirements,
quite ignorant of people. Even after I switched into psychology
and cognitive science, I still maintained my engineering emphasis
upon logic and mechanism. It took a long time for me to realize
that my understanding of human behavior was relevant to my interest in the design of technology. As I watched people struggle
with technology, it became clear that the difficulties were caused
by the technology, not the people.
I was called upon to help analyze the American nuclear power
plant accident at Three Mile Island (the island name comes from
the fact that it is located on a river, three miles south of Middletown in the state of Pennsylvania). In this incident, a rather simple
mechanical failure was misdiagnosed. This led to several days of
difficulties and confusion, total destruction of the reactor, and a
very close call to a severe radiation release, all of which brought
the American nuclear power industry to a complete halt. The operators were blamed for these failures: “human error” was the im
mediate analysis. But the committee I was on discovered that the
plant’s control rooms were so poorly designed that error was inevitable: design was at fault, not the operators. The moral was simple:
we were designing things for people, so we needed to understand
both technology and people. But that’s a difficult step for many
engineers: machines are so logical, so orderly. If we didn’t have
people, everything would work so much better. Yup, that’s how I
used to think.

My work with that committee changed my view of design. Today, I realize that design presents a fascinating interplay of technology and psychology, that the designers must understand both.
Engineers still tend to believe in logic. They often explain to me
in great, logical detail, why their designs are good, powerful, and
wonderful. “Why are people having problems?” they wonder.
“You are being too logical,” I say. “You are designing for people the
way you would like them to be, not for the way they really are.”
When the engineers object, I ask whether they have ever made
an error, perhaps turning on or off the wrong light, or the wrong


one: _The Psychopathology of Everyday Things_ **7**


stove burner. “Oh yes,” they say, “but those were errors.” That’s
the point: even experts make errors. So we must design our machines on the assumption that people will make errors. (Chapter 5
provides a detailed analysis of human error.)