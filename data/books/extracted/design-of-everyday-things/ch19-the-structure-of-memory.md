---
title: "The Structure of Memory"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 19
scraped_date: '2026-01-19'
---

**The Structure of Memory**


_Say aloud the numbers 1, 7, 4, 2, 8. Next, without looking back, repeat_
_them. Try again if you must, perhaps closing your eyes, the better_


three: _Knowledge in the Head and in the World_ **91**


_to “hear” the sound still echoing in mental activity. Have someone_
_read a random sentence to you. What were the words? The memory of_
_the just present is available immediately, clear and complete, without_
_mental effort._
_What did you eat for dinner three days ago? Now the feeling is dif-_
_ferent. It takes time to recover the answer, which is neither as clear nor_
_as complete a remembrance as that of the just present, and the recovery_
_is likely to require considerable mental effort. Retrieval of the past dif-_
_fers from retrieval of the just present. More effort is required, less clarity_
_results. Indeed, the “past” need not be so long ago. Without looking_
_back, what were those digits? For some people, this retrieval now takes_
_time and effort._ (From _Learning and Memory_, Norman, 1982.)


Psychologists distinguish between two major classes of memory:
short-term or working memory, and long-term memory. The two
are quite different, with different implications for design.


**SHORT-TERM OR WORKING MEMORY**


Short-term or working memory (STM) retains the most recent experiences or material that is currently being thought about. It is the
memory of the just present. Information is retained automatically
and retrieved without effort; but the amount of information that
can be retained this way is severely limited. Something like five to
seven items is the limit of STM, with the number going to ten or
twelve if the material is continually repeated, what psychologists
call “rehearsing.”
Multiply 27 times 293 in your head. If you try to do it the same
way you would with paper and pencil, you will almost definitely
be unable to hold all the digits and intervening answers within
STM. You will fail. The traditional method of multiplying is optimized for paper and pencil. There is no need to minimize the burden on working memory because the numbers written on the paper
serve this function (knowledge in the world), so the burden on
STM, on knowledge in the head, is quite limited. There are ways
of doing mental multiplication, but the methods are quite different


**92** _The Design of Everyday Things_


from those using paper and pencil and require considerable training and practice.
Short-term memory is invaluable in the performance of everyday
tasks, in letting us remember words, names, phrases, and parts
of tasks: hence its alternative name, working memory. But the material being maintained in STM is quite fragile. Get distracted by
some other activity and, poof, the stuff in STM disappears. It is capable of holding a postal code or telephone number from the time
you look it up until the time it is used—as long as no distractions
occur. Nine- or ten-digit numbers give trouble, and when the number starts to exceed that—don’t bother. Write it down. Or divide

the number into several shorter segments, transforming the long
number into meaningful chunks.
Memory experts use special techniques, called _mnemonics,_ to
remember amazingly large amounts of material, often after only
a single exposure. One method is to transform the digits into
meaningful segments (one famous study showed how an athlete
thought of digit sequences as running times, and after refining
the method over a long period, could learn incredibly long sequences at one glance). One traditional method used to encode
long sequences of digits is to first transform each digit into a
consonant, then transform the consonant sequence into a memorable phrase. A standard table of conversions of digits to consonants has been around for hundreds of years, cleverly designed
to be easy to learn because the consonants can be derived from
the shape of the digits. Thus, “1” is translated into “t” (or the
similar-sounding “d”), “2” becomes “n,” “3” becomes “m,” “4” is
“r,” and “5” becomes “L” (as in the Roman numeral for 50). The
full table and the mnemonics for learning the pairings are readily found on the Internet by searching for “number-consonant
mnemonic.”

Using the number-consonant transformation, the string
4194780135092770 translates into the letters _rtbrkfstmlspncks,_
which in turn may become, “A hearty breakfast meal has pancakes.” Most people are not experts at retaining long arbitrary


three: _Knowledge in the Head and in the World_ **93**


strings of anything, so although it is interesting to observe memory
wizards, it would be wrong to design systems that assumed this
level of proficiency.
The capacity of STM is surprisingly difficult to measure, because
how much can be retained depends upon the familiarity of the
material. Retention, moreover, seems to be of meaningful items,
rather than of some simpler measure such as seconds or individual
sounds or letters. Retention is affected by both time and the number of items. The number of items is more important than time,
with each new item decreasing the likelihood of remembering all
of the preceding items. The capacity is items because people can
remember roughly the same number of digits and words, and almost the same number of simple three- to five-word phrases. How
can this be? I suspect that STM holds something akin to a pointer
to an already encoded item in long-term memory, which means
the memory capacity is the number of pointers it can keep. This
would account for the fact that the length or complexity of the item
has little impact—simply the number of items. It doesn’t neatly
account for the fact that we make acoustical errors in STM, unless
the pointers are held in a kind of acoustical memory. This remains
an open topic for scientific exploration.
The traditional measures of STM capacity range from five to
seven, but from a practical point of view, it is best to think of it as
holding only three to five items. Does that seem too small a number? Well, when you meet a new person, do you always remember
his or her name? When you have to dial a phone number, do you
have to look at it several times while entering the digits? Even minor distractions can wipe out the stuff we are trying to hold on to
in STM.

What are the design implications? Don’t count on much being
retained in STM. Computer systems often enhance people’s frustration when things go wrong by presenting critical information
in a message that then disappears from the display just when the
person wishes to make use of the information. So how can people
remember the critical information? I am not surprised when people hit, kick, or otherwise attack their computers.


**94** _The Design of Everyday Things_


I have seen nurses write down critical medical information

about their patients on their hands because the critical information would disappear if the nurse was distracted for a moment by
someone asking a question. The electronic medical records systems
automatically log out users when the system does not appear to
be in use. Why the automatic logouts? To protect patient privacy.
The cause may be well motivated, but the action poses severe challenges to nurses who are continually being interrupted in their
work by physicians, co-workers, or patient requests. While they
are attending to the interruption, the system logs them out, so
they have to start over again. No wonder these nurses wrote down
the knowledge, although this then negated much of the value of
the computer system in minimizing handwriting errors. But what
else were they to do? How else to get at the critical information?
They couldn’t remember it all: that’s why they had computers.
The limits on our short-term memory systems caused by interfering tasks can be mitigated by several techniques. One is through
the use of multiple sensory modalities. Visual information does
not much interfere with auditory, actions do not interfere much
with either auditory or written material. Haptics (touch) is also
minimally interfering. To maximize efficiency of working memory
it is best to present different information over different modalities: sight, sound, touch (haptics), hearing, spatial location, and
gestures. Automobiles should use auditory presentation of driving instructions and haptic vibration of the appropriate side of the
driver’s seat or steering wheel to warn when drivers leave their
lanes, or when there are other vehicles to the left or right, so as
not to interfere with the visual processing of driving information.
Driving is primarily visual, so the use of auditory and haptic modalities minimizes interference with the visual task.


**LONG-TERM MEMORY**


Long-term memory (LTM) is memory for the past. As a rule, it
takes time for information to get into LTM and time and effort to
get it out again. Sleep seems to play an important role in strengthening the memories of each day’s experiences. Note that we do


three: _Knowledge in the Head and in the World_ **95**


not remember our experiences as an exact recording; rather, as
bits and pieces that are reconstructed and interpreted each time
we recover the memories, which means they are subject to all the
distortions and changes that the human explanatory mechanism
imposes upon life. How well we can ever recover experiences and
knowledge from LTM is highly dependent upon how the material
was interpreted in the first place. What is stored in LTM under one
interpretation probably cannot be found later on when sought under some other interpretation. As for how large the memory is, nobody really knows: giga- or tera-items. We don’t even know what
kinds of units should be used. Whatever the size, it is so large as
not to impose any practical limit.
The role of sleep in the strengthening of LTM is still not well understood, but there are numerous papers investigating the topic.
One possible mechanism is that of rehearsal. It has long been
known that rehearsal of material—mentally reviewing it while still
active in working memory (STM)—is an important component of
the formation of long-term memory traces. “Whatever makes you
rehearse during sleep is going to determine what you remember
later, and conversely, what you’re going to forget,” said Professor
Ken Paller of Northwestern University, one of the authors of a recent study on the topic (Oudiette, Antony, Creery, and Paller, 2013).
But although rehearsal in sleep strengthens memories, it might
also falsify them: “Memories in our brain are changing all of the
time. Sometimes you improve memory storage by rehearsing all
the details, so maybe later you remember better—or maybe worse
if you’ve embellished too much.”
Remember how you answered this question from Chapter 2?


_In the house you lived in three houses ago, as you entered the front door,_
_was the doorknob on the left or right?_


For most people, the question requires considerable effort just to
recall which house is involved, plus one of the special techniques
described in Chapter 2 for putting yourself back at the scene and
reconstructing the answer. This is an example of procedural mem

**96** _The Design of Everyday Things_


ory, a memory for how we do things, as opposed to declarative
memory, the memory for factual information. In both cases, it can
take considerable time and effort to get to the answer. Moreover,
the answer is not directly retrieved in a manner analogous to the
way we read answers from books or websites. The answer is a reconstruction of the knowledge, so it is subject to biases and distortions. Knowledge in memory is meaningful, and at the time of
retrieval, a person might subject it to a different meaningful interpretation than is wholly accurate.
A major difficulty with LTM is in organization. How do we find
the things we are trying to remember? Most people have had the
“tip of the tongue” experience when trying to remember a name
or word: there is a feeling of knowing, but the knowledge is not
consciously available. Sometime later, when engaged in some
other, different activity, the name may suddenly pop into the
conscious mind. The way by which people retrieve the needed
knowledge is still unknown, but probably involves some form
of pattern-matching mechanism coupled with a confirmatory process that checks for consistency with the required knowledge. This
is why when you search for a name but continually retrieve the
wrong name, you know it is wrong. Because this false retrieval impedes the correct retrieval, you have to turn to some other activity
to allow the subconscious memory retrieval process to reset itself.
Because retrieval is a reconstructive process, it can be erroneous.
We may reconstruct events the way we would prefer to remember
them, rather than the way we experienced them. It is relatively
easy to bias people so that they form false memories, “remembering” events in their lives with great clarity, even though they never
occurred. This is one reason that eyewitness testimony in courts of
law is so problematic: eyewitnesses are notoriously unreliable. A
huge number of psychological experiments show how easy it is to
implant false memories into people’s minds so convincingly that
people refuse to admit that the memory is of an event that never
happened.
Knowledge in the head is actually knowledge in memory: internal knowledge. If we examine how people use their memories and


three: _Knowledge in the Head and in the World_ **97**


how they retrieve knowledge, we discover a number of categories.
Two are important for us now:


1. **Memory for arbitrary things.** The items to be retained seem arbitrary, with no meaning and no particular relationship to one another
or to things already known.
2. **Memory for meaningful things.** The items to be retained form
meaningful relationships with themselves or with other things already known.


**MEMORY FOR ARBITRARY AND MEANINGFUL THINGS**


Arbitrary knowledge can be classified as the simple remembering
of things that have no underlying meaning or structure. A good
example is the memory of the letters of the alphabet and their ordering, the names of people, and foreign vocabulary, where there
appears to be no obvious structure to the material. This also applies to the learning of the arbitrary key sequences, commands,
gestures, and procedures of much of our modern technology: This
is rote learning, the bane of modern existence.
Some things do require rote learning: the letters of the alphabet, for
example, but even here we add structure to the otherwise meaningless list of words, turning the alphabet into a song, using the
natural constraints of rhyme and rhythm to create some structure.
Rote learning creates problems. First, because what is being
learned is arbitrary, the learning is difficult: it can take considerable time and effort. Second, when a problem arises, the
memorized sequence of actions gives no hint of what has gone
wrong, no suggestion of what might be done to fix the problem.
Although some things are appropriate to learn by rote, most are
not. Alas, it is still the dominant method of instruction in many
school systems, and even for much adult training. This is how
some people are taught to use computers, or to cook. It is how we
have to learn to use some of the new (poorly designed) gadgets
of our technology.
We learn arbitrary associations or sequences by artificially providing structure. Most books and courses on methods for improv

**98** _The Design of Everyday Things_


ing memory (mnemonics) use a variety of standard methods for
providing structure, even for things that might appear completely
arbitrary, such as grocery lists, or matching the names of people to
their appearance. As we saw in the discussion of these methods for
STM, even strings of digits can be remembered if they can be associated with meaningful structures. People who have not received
this training or who have not invented some methods themselves
often try to manufacture some artificial structure, but these are often rather unsatisfactory, which is why the learning is so bad.
Most things in the world have a sensible structure, which tremendously simplifies the memory task. When things make sense,
they correspond to knowledge that we already have, so the new
material can be understood, interpreted, and integrated with previously acquired material. Now we can use rules and constraints
to help understand what things go together. Meaningful structure
can organize apparent chaos and arbitrariness.
Remember the discussion of conceptual models in Chapter 1?
Part of the power of a good conceptual model lies in its ability to
provide meaning to things. Let’s look at an example to show how
a meaningful interpretation transforms an apparently arbitrary
task into a natural one. Note that the appropriate interpretation
may not at first be obvious; it, too, is knowledge and has to be
discovered.

A Japanese colleague, Professor Yutaka Sayeki of the University
of Tokyo, had difficulty remembering how to use the turn signal
switch on his motorcycle’s left handlebar. Moving the switch forward signaled a right turn; backward, a left turn. The meaning of
the switch was clear and unambiguous, but the direction in which
it should be moved was not. Sayeki kept thinking that because
the switch was on the left handlebar, pushing it forward should
signal a left turn. That is, he was trying to map the action “push
the left switch forward” to the intention “turn left,” which was
wrong. As a result, he had trouble remembering which switch direction should be used for which turning direction. Most motorcycles have the turn-signal switch mounted differently, rotated
90 degrees, so that moving it left signals a left turn; moving it


three: _Knowledge in the Head and in the World_ **99**


right, a right turn. This mapping is easy to learn (it is an example
of a natural mapping, discussed at the end of this chapter). But the
turn switch on Sayeki’s motorcycle moved forward and back, not
left and right. How could he learn it?
Sayeki solved the problem by reinterpreting the action. Consider
the way the handlebars of the motorcycle turn. For a left turn, the
left handlebar moves backward. For a right turn, the left handlebar
moves forward. The required switch movements exactly paralleled
the handlebar movements. If the task is conceptualized as signaling the direction of motion of the handlebars rather than the direction of the motorcycle, the switch motion can be seen to mimic the
desired motion; finally we have a natural mapping.
When the motion of the switch seemed arbitrary, it was difficult to
remember. Once Professor Sayeki had invented a meaningful relationship, he found it easy to remember the proper switch operation. (Experienced riders will point out that this conceptual model is wrong: to
turn a bike, one first steers in the opposite direction of the turn. This is
discussed as Example 3 in the next section, “Approximate Models.”)
The design implications are clear: provide meaningful structures. Perhaps a better way is to make memory unnecessary: put
the required information in the world. This is the power of the
traditional graphical user interface with its old-fashioned menu
structure. When in doubt, one could always examine all the menu
items until the desired one was found. Even systems that do not
use menus need to provide some structure: appropriate constraints
and forcing functions, natural good mapping, and all the tools of
feedforward and feedback. The most effective way of helping people remember is to make it unnecessary.