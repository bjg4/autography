---
title: "When Good Design Isn’t Enough"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 36
scraped_date: '2026-01-19'
---

**When Good Design Isn’t Enough**


**WHEN PEOPLE REALLY ARE AT FAULT**


I am sometimes asked whether it is really right to say that people
are never at fault, that it is always bad design. That’s a sensible
question. And yes, of course, sometimes it is the person who is
at fault.

Even competent people can lose competency if sleep deprived, fatigued, or under the influence of drugs. This is why we have laws
banning pilots from flying if they have been drinking within some
specified period and why we limit the number of hours they can
fly without rest. Most professions that involve the risk of death or
injury have similar regulations about drinking, sleep, and drugs.
But everyday jobs do not have these restrictions. Hospitals often require their staff to go without sleep for durations that far exceed the
safety requirements of airlines. Why? Would you be happy having a
sleep-deprived physician operating on you? Why is sleep deprivation considered dangerous in one situation and ignored in another?
Some activities have height, age, or strength requirements.
Others require considerable skills or technical knowledge: people


**210** _The Design of Everyday Things_


not trained or not competent should not be doing them. That is
why many activities require government-approved training and licensing. Some examples are automobile driving, airplane piloting,
and medical practice. All require instructional courses and tests.
In aviation, it isn’t sufficient to be trained: pilots must also keep
in practice by flying some minimum number of hours per month.
Drunk driving is still a major cause of automobile accidents: this
is clearly the fault of the drinker. Lack of sleep is another major
culprit in vehicle accidents. But because people occasionally are
at fault does not justify the attitude that assumes they are always
at fault. The far greater percentage of accidents is the result of poor
design, either of equipment or, as is often the case in industrial
accidents, of the procedures to be followed.
As noted in the discussion of deliberate violations earlier in this

chapter (page 169), people will sometimes deliberately violate
procedures and rules, perhaps because they cannot get their jobs
done otherwise, perhaps because they believe there are extenuating circumstances, and sometimes because they are taking the
gamble that the relatively low probability of failure does not apply
to them. Unfortunately, if someone does a dangerous activity that
only results in injury or death one time in a million, that can lead
to hundreds of deaths annually across the world, with its 7 billion
people. One of my favorite examples in aviation is of a pilot who,
after experiencing low oil-pressure readings in all three of his engines, stated that it must be an instrument failure because it was a
one-in-a-million chance that the readings were true. He was right
in his assessment, but unfortunately, he was the one. In the United
States alone there were roughly 9 million flights in 2012. So, a onein-a-million chance could translate into nine incidents.

Sometimes, people really are at fault.


**Resilience Engineering**


In industrial applications, accidents in large, complex systems
such as oil wells, oil refineries, chemical processing plants, electrical power systems, transportation, and medical services can have
major impacts on the company and the surrounding community.


five: _Human Error? No, Bad Design_ **211**


Sometimes the problems do not arise in the organization but outside it, such as when fierce storms, earthquakes, or tidal waves
demolish large parts of the existing infrastructure. In either case,
the question is how to design and manage these systems so that
they can restore services with a minimum of disruption and damage. An important approach is _resilience engineering,_ with the goal
of designing systems, procedures, management, and the training
of people so they are able to respond to problems as they arise. It
strives to ensure that the design of all these things—the equipment,
procedures, and communication both among workers and also externally to management and the public—are continually being assessed, tested, and improved.
Thus, major computer providers can deliberately cause errors in
their systems to test how well the company can respond. This is done
by deliberately shutting down critical facilities to ensure that the
backup systems and redundancies actually work. Although it might
seem dangerous to do this while the systems are online, serving real
customers, the only way to test these large, complex systems is by doing so. Small tests and simulations do not carry the complexity, stress
levels, and unexpected events that characterize real system failures.
As Erik Hollnagel, David Woods, and Nancy Leveson, the authors of an early influential series of books on the topic, have skillfully summarized:


_Resilience engineering is a paradigm for safety management that fo-_
_cuses on how to help people cope with complexity under pressure to_
_achieve success. It strongly contrasts with what is typical today—a_
_paradigm of tabulating error as if it were a thing, followed by interven-_
_tions to reduce this count. A resilient organisation treats safety as a core_
_value, not a commodity that can be counted. Indeed, safety shows itself_
_only by the events that do not happen! Rather than view past success_
_as a reason to ramp down investments, such organisations continue to_
_invest in anticipating the changing potential for failure because they_
_appreciate that their knowledge of the gaps is imperfect and that their_
_environment constantly changes. One measure of resilience is therefore_
_the ability to create foresight—to anticipate the changing shape of risk,_


**212** _The Design of Everyday Things_


_before failure and harm occurs._ (Reprinted by permission of the publishers.


Hollnagel, Woods, & Leveson, 2006, p. 6.)