---
title: "Natural Mapping"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 23
scraped_date: '2026-01-19'
---

**Natural Mapping**


Mapping, a topic from Chapter 1, provides a good example of
the power of combining knowledge in the world with that in the
head. Did you ever turn the wrong burner of a stove on or off?
You would think that doing it correctly would be an easy task.
A simple control turns the burner on, controls the temperature,
and allows the burner to be turned off. In fact, the task appears to
be so simple that when people do it wrong, which happens more
frequently than you might have thought, they blame themselves:
“How could I be so stupid as to do this simple task wrong?” they
think to themselves. Well, it isn’t so simple, and it is not their fault:
even as simple a device as the everyday kitchen stove is frequently
badly designed, in a way that guarantees the errors.
Most stoves have only four burners and four controls in oneto-one correspondence. Why is it so hard to remember four things?


three: _Knowledge in the Head and in the World_ **113**


**A.**


**C.**



**B.**


**BACK** **FRONT** **BACK** **FRONT** **BACK** **FRONT** **FRONT** **BACK**


**D.**


**FIGURE 3.2.** **Mappings of Stove Controls with Burners.** With the traditional arrangement of stove burners shown in Figures A and B, the burners
are arranged in a rectangle and the controls in a linear line. Usually there
is a partial natural mapping, with the left two controls operating the left
burners and the right two controls operating the right burners. Even so,
there are four possible mappings of controls to burners, all four of which
are used on commercial stoves. The only way to know which control
works which burner is to read the labels. But if the controls were also in a
rectangle (Figure C) or the burners staggered (Figure D), no labels would
be needed. Learning would be easy; errors would be reduced.



In principle, it should be easy to remember the relationship between the controls and the burners. In practice, however, it is almost impossible. Why? Because of the poor mappings between the
controls and the burners. Look at Figure 3.2, which depicts four
possible mappings between the four burners and controls. Figures
3.2A and B show how not to map one dimension onto two. Figures
3.2C and D show two ways of doing it properly: arrange the controls in two dimensions (C) or stagger the burners (D) so they can
be ordered left to right.


**114** _The Design of Everyday Things_


To make matters worse, stove manufacturers cannot agree upon
what the mapping should be. If all stoves used the same arrangement of controls, even if it is unnatural, everyone could learn it
once and forever after get things right. As the legend of Figure
3.2 points out, even if the stove manufacturer is nice enough to
ensure that each pair of controls operates the pair of burners on its
side, there are still four possible mappings. All four are in common
use. Some stoves arrange the controls in a vertical line, giving even
more possible mappings. Every stove seems to be different. Even
different stoves from the same manufacturer differ. No wonder

people have trouble, leading their food to go uncooked, and in the
worst cases, leading to fire.
Natural mappings are those where the relationship between the
controls and the object to be controlled (the burners, in this case)
is obvious. Depending upon circumstances, natural mappings will
employ spatial cues. Here are three levels of mapping, arranged in
decreasing effectiveness as memory aids:


 - **Best mapping:** Controls are mounted directly on the item to be con
trolled.

 - **Second-best mapping:** Controls are as close as possible to the object

to be controlled.

 - **Third-best mapping:** Controls are arranged in the same spatial configuration as the objects to be controlled.


In the ideal and second-best cases, the mappings are indeed clear
and unambiguous.
Want excellent examples of natural mapping? Consider gesturecontrolled faucets, soap dispensers, and hand dryers. Put your
hands under the faucet or soap dispenser and the water or soap
appears. Wave your hand in front of the paper towel dispenser
and out pops a new towel, or in the case of blower-controlled
hand dryers, simply put your hands beneath or into the dryer
and the drying air turns on. Mind you, although the mappings of
these devices are appropriate, they do have problems. First, they
often lack signifiers, hence they lack discoverability. The controls


three: _Knowledge in the Head and in the World_ **115**


are often invisible, so we sometimes put our hands under faucets
expecting to receive water, but wait in vain: these are mechanical faucets that require handle turning. Or the water turns on
and then stops, so we wave our hands up and down, hoping to
find the precise location where the water turns on. When I wave
my hand in front of the towel dispenser but get no towel, I do
not know whether this means the dispenser is broken or out of
towels; or that I did the waving wrong, or in the wrong place; or
that maybe this doesn’t work by gesture, but I must push, pull,
or turn something. The lack of signifiers is a real drawback. These
devices aren’t perfect, but at least they got the mapping right.
In the case of stove controls, it is obviously not possible to put
the controls directly on the burners. In most cases, it is also dangerous to put the controls adjacent to the burners, not only for fear
of burning the person using the stove, but also because it would
interfere with the placement of cooking utensils. Stove controls are
usually situated on the side, back, or front panel of the stove, in
which case they ought to be arranged in spatial harmony with the
burners, as in Figures 3.2 C and D.
With a good natural mapping, the relationship of the controls to
the burner is completely contained in the world; the load on human memory is much reduced. With a bad mapping, however, a
burden is placed upon memory, leading to more mental effort and
a higher chance of error. Without a good mapping, people new to
the stove cannot readily determine which burner goes with which
control and even frequent users will still occasionally err.
Why do stove designers insist on arranging the burners in a
two-dimensional rectangular pattern, and the controls in a onedimensional row? We have known for roughly a century just
how bad such an arrangement is. Sometimes the stove comes
with clever little diagrams to indicate which control works which
burner. Sometimes there are labels. But the proper natural mapping requires no diagrams, no labels, and no instructions.
The irony about stove design is that it isn’t hard to do right. Textbooks of ergonomics, human factors, psychology, and industrial
engineering have been demonstrating both the problems and the


**116** _The Design of Everyday Things_


solutions for over fifty years. Some stove manufacturers do use
good designs. Oddly, sometimes the best and the worst designs are
manufactured by the same companies and are illustrated side by
side in their catalogs. Why do users still purchase stoves that cause
so much trouble? Why not revolt and refuse to buy them unless the
controls have an intelligent relationship to the burners?
The problem of the stovetop may seem trivial, but similar mapping problems exist in many situations, including commercial and
industrial settings, where selecting the wrong button, dial, or lever
can lead to major economic impact or even fatalities.
In industrial settings good mapping is of special importance,
whether it is a remotely piloted airplane, a large building crane
where the operator is at a distance from the objects being manipulated, or even in an automobile where the driver might wish to
control temperature or windows while driving at high speeds or in
crowded streets. In these cases, the best controls usually are spatial
mappings of the controls to the items being controlled. We see this
done properly in most automobiles where the driver can operate
the windows through switches that are arranged in spatial correspondence to the windows.
Usability is not often thought about during the purchasing process. Unless you actually test a number of units in a realistic environment, doing typical tasks, you are not likely to notice the ease or
difficulty of use. If you just look at something, it appears straightforward enough, and the array of wonderful features seems to be
a virtue. You may not realize that you won’t be able to figure out
how to use those features. I urge you to test products before you buy
them. Before purchasing a new stovetop, pretend you are cooking
a meal. Do it right there in the store. Do not be afraid to make mistakes or ask stupid questions. Remember, any problems you have
are probably the design’s fault, not yours.
A major obstacle is that often the purchaser is not the user. Appliances may be in a home when people move in. In the office, the
purchasing department orders equipment based upon such factors
as price, relationships with the supplier, and perhaps reliability:
usability is seldom considered. Finally, even when the purchaser


three: _Knowledge in the Head and in the World_ **117**


is the end user, it is sometimes necessary to trade off one desirable
feature for an undesirable one. In the case of my family’s stove,
we did not like the arrangement of controls, but we bought the
stove anyway: we traded off the layout of the burner controls for
another design feature that was more important to us and available
only from one manufacturer. But why should we have to make a
tradeoff? It wouldn’t be hard for all stove manufacturers to use

natural mappings, or at the least, to standardize their mappings.


**Culture and Design:**
**Natural Mappings Can Vary with Culture**


I was in Asia, giving a talk. My computer was connected to a projector and I was given a remote controller for advancing through
the illustrations for my talk. This one had two buttons, one above
the other. The title was already displayed on the screen, so when I
started, all I had to do was to advance to the first photograph in my
presentation, but when I pushed the upper button, to my amazement I went backward through my illustrations, not forward.
“How could this happen?” I wondered. To me, top means forward;
bottom, backward. The mapping is clear and obvious. If the buttons
had been side by side, then the control would have been ambiguous: which comes first, right or left? This controller appeared to use
an appropriate mapping of top and bottom. Why was it working
backward? Was this yet another example of poor design?
I decided to ask the audience. I showed them the controller and

asked: “To get to my next picture, which button should I push, the
top or the bottom?” To my great surprise, the audience was split in
their responses. Many thought that it should be the top button, just
as I had thought. But a large number thought it should be the bottom.
What’s the correct answer? I decided to ask this question to my
audiences around the world. I discovered that they, too, were split
in their opinions: some people firmly believe that it is the top button and some, just as firmly, believe it is the bottom button. Everyone is surprised to learn that someone else might think differently.
I was puzzled until I realized that this was a point-of-view problem, very similar to the way different cultures view time. In some


**118** _The Design of Everyday Things_


cultures, time is represented mentally as if it were a road stretching
out ahead of the person. As a person moves through time, the person moves forward along the time line. Other cultures use the same
representation, except now it is the person who is fixed and it is
time that moves: an event in the future moves toward the person.
This is precisely what was happening with the controller. Yes,
the top button does cause something to move forward, but the
question is, what is moving? Some people thought that the person
would move through the images, other people thought the images
would move. People who thought that they moved through the
images wanted the top button to indicate the next one. People who
thought it was the illustrations that moved would get to the next
image by pushing the bottom button, causing the images to move
toward them.

Some cultures represent the time line vertically: up for the future,
down for the past. Other cultures have rather different views. For
example, does the future lie ahead or behind? To most of us, the
question makes no sense: of course, the future lies ahead—the past
is behind us. We speak this way, discussing the “arrival” of the future; we are pleased that many unfortunate events of the past have
been “left behind.”

But why couldn’t the past be in front of us and the future behind? Does that sound strange? Why? We can see what is in front
of us, but not what is behind, just as we can remember what happened in the past, but we can’t remember the future. Not only that,
but we can remember recent events much more clearly than longpast events, captured neatly by the visual metaphor in which the
past lines up before us, the most recent events being the closest
so that they are clearly perceived (remembered), with long-past
events far in the distance, remembered and perceived with difficulty. Still sound weird? This is how the South American Indian
group, the Aymara, represent time. When they speak of the future,
they use the phrase _back days_ and often gesture behind them. Think
about it: it is a perfectly logical way to view the world.
If time is displayed along a horizontal line, does it go from left to
right or right to left? Either answer is correct because the choice is


three: _Knowledge in the Head and in the World_ **119**


arbitrary, just as the choice of whether text should be strung along
the page from left to right or right to left is arbitrary. The choice of
text direction also corresponds to people’s preference for time direction. People whose native language is Arabic or Hebrew prefer
time to flow from right to left (the future being toward the left),
whereas those who use a left-to-right writing system have time
flowing in the same direction, so the future is to the right.
But wait: I’m not finished. Is the time line relative to the person
or relative to the environment? In some Australian Aborigine societies, time moves relative to the environment based on the direction
in which the sun rises and sets. Give people from this community
a set of photographs structured in time (for example, photographs
of a person at different ages or a child eating some food) and ask
them to order the photographs in time. People from technological
cultures would order the pictures from left to right, most recent
photo to the right or left, depending upon how their printed language was written. But people from these Australian communities
would order them east to west, most recent to the west. If the person were facing south, the photo would be ordered left to right. If
the person were facing north, the photos would be ordered right to
left. If the person were facing west, the photos would be ordered
along a vertical line extending from the body outward, outwards
being the most recent. And, of course, were the person facing east,
the photos would also be on a line extending out from the body,
but with the most recent photo closest to the body.
The choice of metaphor dictates the proper design for interaction. Similar issues show up in other domains. Consider the standard problem of scrolling the text in a computer display. Should
the scrolling control move the text or the window? This was a
fierce debate in the early years of display terminals, long before the
development of modern computer systems. Eventually, there was
mutual agreement that the cursor arrow keys—and then, later on,
the mouse—would follow the moving window metaphor. Move
the window down to see more text at the bottom of the screen.

What this meant in practice is that to see more text at the bottom
of the screen, move the mouse down, which moves the window


**120** _The Design of Everyday Things_


down, so that the text moves up: the mouse and the text move
in opposite directions. With the moving text metaphor, the mouse
and the text move in the same directions: move the mouse up and
the text moves up. For over two decades, everyone moved the
scrollbars and mouse down in order to make the text move up.
But then smart displays with touch-operated screens arrived.
Now it was only natural to touch the text with the fingers and
move it up, down, right, or left directly: the text moved in the same
direction as the fingers. The moving text metaphor became prevalent. In fact, it was no longer thought of as a metaphor: it was
real. But as people switched back and forth between traditional
computer systems that used the moving window metaphor and
touch-screen systems that used the moving text model, confusion
reigned. As a result, one major manufacturer of both computers
and smart screens, Apple, switched everything to the moving text
model, but no other company followed Apple’s lead. As I write
this, the confusion still exists. How will it end? I predict the demise of the moving window metaphor: touch-screens and control
pads will dominate, which will cause the moving text model to
take over. All systems will move the hands or controls in the same
direction as they wish the screen images to move. Predicting technology is relatively easy compared to predictions of human behavior, or in this case, the adoption of societal conventions. Will this
prediction be true? You will be able to judge for yourself.
Similar issues occurred in aviation with the pilot’s attitude indicator, the display that indicates the airplane’s orientation (roll or
bank and pitch). The instrument shows a horizontal line to indicate
the horizon with a silhouette of an airplane seen from behind. If
the wings are level and on a line with the horizon, the airplane
is flying in level flight. Suppose the airplane turns to the left,
so it banks (tilts) left. What should the display look like? Should
it show a left-tilting airplane against a fixed horizon, or a fixed
airplane against a right-tilting horizon? The first is correct from the
viewpoint of someone watching the airplane from behind, where
the horizon is always horizontal: this type of display is called
_outside-in._ The second is correct from the viewpoint of the pilot,


three: _Knowledge in the Head and in the World_ **121**


where the airplane is always stable and fixed in position, so that
when the airplane banks, the horizon tilts: this type of display is
called _inside-out._

In all these cases, every point of view is correct. It all depends
upon what you consider to be moving. What does all this mean for
design? What is natural depends upon point of view, the choice
of metaphor, and therefore, the culture. The design difficulties
occur when there is a switch in metaphors. Airplane pilots have
to undergo training and testing before they are allowed to switch
from one set of instruments (those with an outside-in metaphor, for
example) to the other (those with the inside-out metaphor). When
countries decided to switch which side of the road cars would

drive on, the temporary confusion that resulted was dangerous.
(Most places that switched moved from left-side driving to rightside, but a few, notably Okinawa, Samoa, and East Timor, switched
from right to left.) In all these cases of convention switches, people
eventually adjusted. It is possible to break convention and switch
metaphors, but expect a period of confusion until people adapt to
the new system.


**122** _The Design of Everyday Things_


**C H A P T E R F O U R**

###### KNOWING WHAT TO DO: CONSTRAINTS, DISCOVERABILITY, AND FEEDBACK


How do we determine how to operate something that
we have never seen before? We have no choice but to

combine knowledge in the world with that in the head.
Knowledge in the world includes perceived affordances
and signifiers, the mappings between the parts that appear to
be controls or places to manipulate and the resulting actions,
and the physical constraints that limit what can be done.
Knowledge in the head includes conceptual models; cultural,
semantic, and logical constraints on behavior; and analogies
between the current situation and previous experiences with
other situations. Chapter 3 was devoted to a discussion of how
we acquire knowledge and use it. There, the major emphasis
was upon the knowledge in the head. This chapter focuses
upon the knowledge in the world: how designers can provide
the critical information that allows people to know what to do,
even when experiencing an unfamiliar device or situation.
Let me illustrate with an example: building a motorcycle
from a Lego set (a children’s construction toy). The Lego motorcycle shown in Figure 4.1 has fifteen pieces, some rather specialized. Of those fifteen pieces, only two pairs are alike—two
rectangles with the word _police_ on them, and the two hands of


**123**


**FIGURE 4.1.** **Lego Motorcycle.** The toy Lego motorcycle is shown assembled (A) and
in pieces (B). It has fifteen pieces so cleverly constructed that even an adult can put
them together. The design exploits constraints to specify just which pieces fit where.
Physical constraints limit alternative placements. Cultural and semantic constraints provide the necessary clues for further decisions. For example, cultural constraints dictate
the placement of the three lights (red, blue, and yellow) and semantic constraints stop
the user from putting the head backward on the body or the pieces labeled “police”
upside down.


the policeman. Other pieces match one another in size and shape
but are different colors. So, a number of the pieces are physically
interchangeable—that is, the physical constraints are not sufficient
to identify where they go—but the appropriate role for every single
piece of the motorcycle is still unambiguously determined. How?
By combining cultural, semantic, and logical constraints with the
physical ones. As a result, it is possible to construct the motorcycle
without any instructions or assistance.
In fact, I did the experiment. I asked people to put together the
parts; they had never seen the finished structure and were not even
told that it was a motorcycle (although it didn’t take them long to
figure this out). Nobody had any difficulty.
The visible affordances of the pieces were important in determining just how they fit together. The cylinders and holes characteristic of Lego suggested the major construction rule. The sizes and
shapes of the parts suggested their operation. Physical constraints
limited what parts would fit together. Cultural and semantic constraints provided strong restrictions on what would make sense
for all but one of the remaining pieces, and with just one piece left
and only one place it could possibly go, simple logic dictated the


**124** _The Design of Everyday Things_


placement. These four classes of constraints—physical, cultural,
semantic, and logical—seem to be universal, appearing in a wide
variety of situations.
Constraints are powerful clues, limiting the set of possible actions. The thoughtful use of constraints in design lets people readily determine the proper course of action, even in a novel situation.


**Four Kinds of Constraints:**

**Physical, Cultural, Semantic, and Logical**


**PHYSICAL CONSTRAINTS**


Physical limitations constrain possible operations. Thus, a large
peg cannot fit into a small hole. With the Lego motorcycle, the
windshield would fit in only one place. The value of physical constraints is that they rely upon properties of the physical world for
their operation; no special training is necessary. With the proper
use of physical constraints, there should be only a limited number
of possible actions—or, at least, desired actions can be made obvious, usually by being especially salient.
Physical constraints are made more effective and useful if they are
easy to see and interpret, for then the set of actions is restricted before anything has been done. Otherwise, a physical constraint prevents a wrong action from succeeding only after it has been tried.
The traditional cylindrical battery, Figure 4.2A, lacks sufficient
physical constraints. It can be put into battery compartments in
two orientations: one that is correct, the other of which can damage
the equipment. The instructions in Figure 4.2B show that polarity
is important, yet the inferior signifiers inside the battery compartment makes it very difficult to determine the proper orientation
for the batteries.

Why not design a battery with which it would be impossible to
make an error: use physical constraints so that the battery will fit
only if properly oriented. Alternatively, design the battery or the
electrical contacts so that orientation doesn’t matter.

Figure 4.3 shows a battery that has been designed so that orientation is irrelevant. Both ends of the battery are identical, with the


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **125**


**FIGURE 4.2.** **Cylindrical Battery: Where Constraints Are Needed.** Figure A shows
the traditional cylindrical battery that requires correct orientation in the slot to work
properly (and to avoid damaging the equipment). But look at Figure B, which shows
where two batteries are to be installed. The instructions from the manual are shown as
an overlay to the photograph. They seem simple, but can you see into the dark recess to
figure out which end of each battery goes where? Nope. The lettering is black against
black: slightly raised shapes in the dark plastic.


**FIGURE 4.3.** **Making Battery Orientation**
**Irrelevant.** This photograph shows a battery
whose orientation doesn’t matter; it can be
inserted into the equipment in either possible direction. How? Each end of the battery
has the same three concentric rings, with the
center one on both ends being the “plus” terminal and the middle one being the “minus”
terminal.


positive and negative terminals for the battery being its center and
middle rings, respectively. The contact for the positive polarity is
designed so it contacts only the center ring. Similarly, the contact
for negative polarity touches only the middle ring. Although this
seems to solve the problem, I have only seen this one example of
such a battery: they are not widely available or used.
Another alternative is to invent battery contacts that allow our
existing cylindrical batteries to be inserted in either orientation yet
still work properly: Microsoft has invented this kind of contact,
which it calls InstaLoad, and is attempting to convince equipment
manufacturers to use it.

A third alternative is to design the shape of the battery so that
it can fit in only one way. Most plug-in components do this well,
using shapes, notches, and protrusions to constrain insertion


**126** _The Design of Everyday Things_


to a single orientation. So why can’t our everyday batteries be
the same?

Why does inelegant design persist for so long? This is called the
_legacy problem,_ and it will come up several times in this book. Too
many devices use the existing standard—that is the legacy. If the
symmetrical cylindrical battery were changed, there would also
have to be a major change in a huge number of products. The new
batteries would not work in older equipment, nor the old batteries
in new equipment. Microsoft’s design of contacts would allow us
to continue to use the same batteries we are used to, but the products would have to switch to the new contacts. Two years after Microsoft’s introduction of InstaLoad, despite positive press, I could
find no products that use them—not even Microsoft products.
Locks and keys suffer from a similar problem. Although it is usually easy to distinguish the smooth top part of a key from its jagged
underside, it is difficult to tell from the lock just which orientation of the key is required, especially in dark environments. Many
electrical and electronic plugs and sockets have the same problem.
Although they do have physical constraints to prevent improper
insertion, it is often extremely difficult to perceive their correct orientation, especially when keyholes and electronic sockets are in
difficult-to-reach, dimly lit locations. Some devices, such as USB
plugs, are constrained, but the constraint is so subtle that it takes
much fussing and fumbling to find the correct orientation. Why
aren’t all these devices orientation insensitive?

It is not difficult to design keys and plugs that work regardless of
how they are inserted. Automobile keys that are insensitive to the
orientation have long existed, but not all manufacturers use them.
Similarly, many electrical connectors are insensitive to orientation,
but again, only a few manufacturers use them. Why the resistance?
Some of it results from the legacy concerns about the expense of
massive change. But much seems to be a classic example of corporate thinking: “This is the way we have always done things. We
don’t care about the customer.” It is, of course, true that difficulty
in inserting keys, batteries, or plugs is not a big enough issue to
affect the decision of whether to purchase something, but still, the


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **127**


lack of attention to customer needs on even simple things is often
symptomatic of larger issues that have greater impact.
Note that a superior solution would be to solve the fundamental
need—solving the root need. After all, we don’t really care about
keys and locks: what we need is some way of ensuring that only
authorized people can get access to whatever is being locked.
Instead of redoing the shapes of physical keys, make them irrelevant. Once this is recognized, a whole set of solutions present
themselves: combination locks that do not require keys, or keyless locks that can be operated only by authorized people. One
method is through possession of an electronic wireless device,
such as the identification badges that unlock doors when they
are moved close to a sensor, or automobile keys that can stay in
the pocket or carrying case. Biometric devices could identify the
person through face or voice recognition, fingerprints, or other
biometric measures, such as iris patterns. This approach is discussed in Chapter 3, page 91.


**CULTURAL CONSTRAINTS**


Each culture has a set of allowable actions for social situations.

Thus, in our own culture we know how to behave in a restaurant—
even one we have never been to before. This is how we manage
to cope when our host leaves us alone in a strange room, at a
strange party, with strange people. And this is why we sometimes
feel frustrated, so incapable of action, when we are confronted
with a restaurant or group of people from an unfamiliar culture,
where our normally accepted behavior is clearly inappropriate and
frowned upon. Cultural issues are at the root of many of the problems we have with new machines: there are as yet no universally
accepted conventions or customs for dealing with them.
Those of us who study these things believe that guidelines for
cultural behavior are represented in the mind by schemas, knowledge structures that contain the general rules and information necessary for interpreting situations and for guiding behavior. In some
stereotypical situations (for example, in a restaurant), the schemas
may be very specialized. Cognitive scientists Roger Schank and


**128** _The Design of Everyday Things_


Bob Abelson proposed that in these cases we follow “scripts” that
can guide the sequence of behavior. The sociologist Erving Goffman calls the social constraints on acceptable behavior “frames,”
and he shows how they govern behavior even when a person is in
a novel situation or novel culture. Danger awaits those who deliberately violate the frames of a culture.
The next time you are in an elevator, try violating cultural norms
and see how uncomfortable that makes you and the other people
in the elevator. It doesn’t take much: Stand facing the rear. Or look
directly at some of the passengers. In a bus or streetcar, give your
seat to the next athletic-looking person you see (the act is especially
effective if you are elderly, pregnant, or disabled).
In the case of the Lego motorcycle of Figure 4.1, cultural constraints determine the locations of the three lights of the motorcycle, which are otherwise physically interchangeable. Red is the
culturally defined standard for a brake light, which is placed in
the rear. And a police vehicle often has a blue flashing light on top.
As for the yellow piece, this is an interesting example of cultural
change: few people today remember that yellow used to be a standard headlight color in Europe and a few other locations (Lego
comes from Denmark). Today, European and North American standards require white headlights. As a result, figuring out that the
yellow piece represents a headlight on the front of the motorcycle
is no longer as easy as it used to be. Cultural constraints are likely
to change with time.


**SEMANTIC CONSTRAINTS**


Semantics is the study of meaning. Semantic constraints are those
that rely upon the meaning of the situation to control the set of
possible actions. In the case of the motorcycle, there is only one
meaningful location for the rider, who must sit facing forward. The
purpose of the windshield is to protect the rider’s face, so it must
be in front of the rider. Semantic constraints rely upon our knowledge of the situation and of the world. Such knowledge can be a
powerful and important clue. But just as cultural constraints can
change with time, so, too, can semantic ones. Extreme sports push


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **129**


the boundaries of what we think of as meaningful and sensible.
New technologies change the meanings of things. And creative
people continually change how we interact with our technologies
and one another. When cars become fully automated, communicating among themselves with wireless networks, what will be the
meaning of the red lights on the rear of the auto? That the car is
braking? But for whom would the signal be intended? The other
cars would already know. The red light would become meaningless, so it could either be removed or it could be redefined to indicate some other condition. The meanings of today may not be the
meanings of the future.


**LOGICAL CONSTRAINTS**


The blue light of the Lego motorcycle presents a special problem.
Many people had no knowledge that would help, but after all the
other pieces had been placed on the motorcycle, there was only
one piece left, only one possible place to go. The blue light was
logically constrained.
Logical constraints are often used by home dwellers who undertake repair jobs. Suppose you take apart a leaking faucet to replace
a washer, but when you put the faucet together again, you discover
a part left over. Oops, obviously there was an error: the part should
have been installed. This is an example of a logical constraint.
The natural mappings discussed in Chapter 3 work by providing logical constraints. There are no physical or cultural principles
here; rather, there is a logical relationship between the spatial or
functional layout of components and the things that they affect or
are affected by. If two switches control two lights, the left switch
should work the left light; the right switch, the right light. If the
orientation of the lights and the switches differ, the natural mapping is destroyed.


**CULTURAL NORMS, CONVENTIONS, AND STANDARDS**


Every culture has its own conventions. Do you kiss or shake hands
when meeting someone? If kissing, on which cheek, and how many
times? Is it an air kiss or an actual one? Or perhaps you bow, junior


**130** _The Design of Everyday Things_


person first, and lowest. Or raise hands, or perhaps press them together. Sniff? It is possible to spend a fascinating hour on the Internet exploring the different forms of greetings used by different
cultures. It is also amusing to watch the consternation when people
from more cool, formal countries first encounter people from warmhearted, earthy countries, as one tries to bow and shake hands and
the other tries to hug and kiss even total strangers. It is not so amusing to be one of those people: being hugged or kissed while trying
to shake hands or bow. Or the other way around. Try kissing someone’s cheek three times (left, right, left) when the person expects
only one. Or worse, where he or she expects a handshake. Violation
of cultural conventions can completely disrupt an interaction.
Conventions are actually a form of cultural constraint, usually
associated with how people behave. Some conventions determine
what activities should be done; others prohibit or discourage actions. But in all cases, they provide those knowledgeable of the
culture with powerful constraints on behavior.
Sometimes these conventions are codified into international stan
dards, sometimes into laws, and sometimes both. In the early days
of heavily traveled streets, whether by horses and buggies or by
automobiles, congestion and accidents arose. Over time, conventions developed about which side of the road to drive on, with different conventions in different countries. Who had precedence at
crossings? The first person to get there? The vehicle or person on
the right, or the person with the highest social status? All of these
conventions have applied at one time or another. Today, worldwide
standards govern many traffic situations: Drive on only one side of
the street. The first car into an intersection has precedence. If both
arrive at the same time, the car on the right (or left) has precedence.
When merging traffic lanes, alternate cars—one from that lane,
then one from this. The last rule is more of an informal convention:

it is not part of any rule book that I am aware of, and although it
is very nicely obeyed in the California streets on which I drive, the
very concept would seem strange in some parts of the world.
Sometimes conventions clash. In Mexico, when two cars approach a narrow, one-lane bridge from opposite directions, if a car


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **131**


blinks its headlights, it means, “I got here first and I’m going over
the bridge.” In England, if a car blinks its lights, it means, “I see
you: please go first.” Either signal is equally appropriate and useful, but not if the two drivers follow different conventions. Imagine
a Mexican driver meeting an English driver in some third country.
(Note that driving experts warn against using headlight blinks as
signals because even within any single country, either interpretation is held by many drivers, none of whom imagines someone else
might have the opposite interpretation.)
Ever get embarrassed at a formal dinner party where there appear to be dozens of utensils at each place setting? What do you
do? Do you drink that nice bowl of water or is it for dipping your
fingers to clean them? Do you eat a chicken drumstick or slice of
pizza with your fingers or with a knife and fork?
Do these issues matter? Yes, they do. Violate conventions and
you are marked as an outsider. A rude outsider, at that.


**Applying Affordances, Signifiers, and**
**Constraints to Everyday Objects**


Affordances, signifiers, mappings, and constraints can simplify our
encounters with everyday objects. Failure to properly deploy these
cues leads to problems.


**THE PROBLEM WITH DOORS**


In Chapter 1 we encountered the sad story of my friend who was
trapped between sets of glass doors at a post office, trapped because there were no clues to the doors’ operation. To operate a
door, we have to find the side that opens and the part to be manipulated; in other words, we need to figure out what to do and where
to do it. We expect to find some visible signal, a signifier, for the
correct operation: a plate, an extension, a hollow, an indentation—
something that allows the hand to touch, grasp, turn, or fit into.
This tells us where to act. The next step is to figure out how: we
must determine what operations are permitted, in part by using
the signifiers, in part guided by constraints.


**132** _The Design of Everyday Things_


Doors come in amazing variety. Some open only if a button is
pushed, and some don’t indicate how to open at all, having neither buttons, nor hardware, nor any other sign of their operation. The door might be operated with a foot pedal. Or maybe it
is voice operated, and we must speak the magic phrase (“Open
Simsim!”). In addition, some doors have signs on them, to pull,
push, slide, lift, ring a bell, insert a card, type a password, smile,
rotate, bow, dance, or, perhaps, just ask. Somehow, when a device
as simple as a door has to have a sign telling you whether to pull,
push, or slide, then it is a failure, poorly designed.
Consider the hardware for an unlocked door. It need not have

any moving parts: it can be a fixed knob, plate, handle, or groove.
Not only will the proper hardware operate the door smoothly, but
it will also indicate just how the door is to be operated: it will incorporate clear and unambiguous clues—signifiers. Suppose the
door opens by being pushed. The easiest way to indicate this is to
have a plate at the spot where the pushing should be done.
Flat plates or bars can clearly and unambiguously signify both
the proper action and its location, for their affordances constrain
the possible actions to that of pushing. Remember the discussion
of the fire door and its panic bar in Chapter 2 (Figure 2.5, page 60)?
The panic bar, with its large horizontal surface, often with a secondary color on the part intended to be pushed, provides a good
example of an unambiguous signifier. It very nicely constrains
improper behavior when panicked people press against the door
as they attempt to flee a fire. The best push bars offer both visible
affordances that act as physical constraints on the action, and also
a visible signifier, thereby unobtrusively specifying _what_ to do and
_where_ to do it.

Some doors have appropriate hardware, well placed. The outside
door handles of most modern automobiles are excellent examples
of design. The handles are often recessed receptacles that simultaneously indicate the place and mode of action. Horizontal slits
guide the hand into a pulling position; vertical slits signal a sliding
motion. Strangely enough, the inside door handles for automobiles


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **133**


tell a different story. Here, the designer has faced a different kind
of problem, and the appropriate solution has not yet been found.
As a result, although the outside door handles of cars are often
excellent, the inside ones are often difficult to find, hard to figure
out how to operate, and awkward to use.
From my experience, the worst offenders are cabinet doors. It
is sometimes not even possible to determine where the doors are,
let alone whether and how they are slid, lifted, pushed, or pulled.
The focus on aesthetics may blind the designer (and the purchaser)
to the lack of usability. A particularly frustrating design is that of
the cabinet door that opens outward by being pushed inward. The
push releases the catch and energizes a spring, so that when the hand
is taken away, the door springs open. It’s a very clever design, but
most puzzling to the first-time user. A plate would be the appropriate signal, but designers do not wish to mar the smooth surface of
the door. One of the cabinets in my home has one of these latches
in its glass door. Because the glass affords visibility of the shelves
inside, it is obvious that there is no room for the door to open inward;
therefore, to push the door seems contradictory. New and infrequent users of this door usually reject pushing and open it by pulling, which often requires them to use fingernails, knife blades, or
more ingenious methods to pry it open. A similar, counterintuitive
type of design was the source of my difficulties in emptying the
dirty water from my sink in a London hotel (Figure 1.4, page 17).
Appearances deceive. I have seen people trip and fall when
they attempted to push open a door that worked automatically,
the door opening inward just as they attempted to push against
it. On most subway trains, the doors open automatically at each
station. Not so in Paris. I watched someone on the Paris Métro

try to get off the train and fail. When the train came to his station,
he got up and stood patiently in front of the door, waiting for it
to open. It never opened. The train simply started up again and
went on to the next station. In the Métro, you have to open the
doors yourself by pushing a button, or depressing a lever, or sliding them (depending upon which kind of car you happen to be
on). In some transit systems, the passenger is supposed to operate


**134** _The Design of Everyday Things_


the door, but in others this is forbidden. The frequent traveler is
continually confronted with this kind of situation: the behavior
that is appropriate in one place is inappropriate in another, even
in situations that appear to be identical. Known cultural norms
can create comfort and harmony. Unknown norms can lead to discomfort and confusion.


**THE PROBLEM WITH SWITCHES**


When I give talks, quite often my first demonstration needs no
preparation. I can count on the light switches of the room or auditorium to be unmanageable. “Lights, please,” someone will say.
Then fumble, fumble, fumble. Who knows where the switches are
and which lights they control? The lights seem to work smoothly
only when a technician is hired to sit in a control room somewhere,
turning them on and off.
The switch problems in an auditorium are annoying, but similar
problems in industry could be dangerous. In many control rooms,
row upon row of identical-looking switches confront the operators.
How do they avoid the occasional error, confusion, or accidental
bumping against the wrong control? Or mis-aim? They don’t. Fortunately, industrial settings are usually pretty robust. A few errors
every now and then are not important—usually.
One type of popular small airplane has identical-looking switches
for flaps and for landing gear, right next to one another. You might
be surprised to learn how many pilots, while on the ground, have
decided to raise the flaps and instead raised the wheels. This very
expensive error happened frequently enough that the National
Transportation Safety Board wrote a report about it. The analysts
politely pointed out that the proper design principles to avoid these
errors had been known for fifty years. Why were these design
errors still being made?
Basic switches and controls should be relatively simple to design well. But there are two fundamental difficulties. The first is
to determine what type of device they control; for example, flaps
or landing gear. The second is the mapping problem, discussed
extensively in Chapters 1 and 3; for example, when there are many


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **135**


lights and an array of switches, which switch controls which light?
The switch problem becomes serious only where there are many
of them. It isn’t a problem in situations with one switch, and it is
only a minor problem where there are two switches. But the difficulties mount rapidly with more than two switches at the same
location. Multiple switches are more likely to appear in offices, auditoriums, and industrial locations than in homes.
With complex installations, where there are numerous lights and
switches, the light controls seldom fit the needs of the situation.
When I give talks, I need a way to dim the light hitting the projection screen so that images are visible, but keep enough light on
the audience so that they can take notes (and I can monitor their
reaction to the talk). This kind of control is seldom provided. Electricians are not trained to do task analyses.
Whose fault is this? Probably nobody’s. Blaming a person is seldom appropriate or useful, a point I return to in Chapter 5. The
problem is probably due to the difficulties of coordinating the different professions involved in installing light controls.


**FIGURE 4.4.** **Incomprehensible Light Switches.** Banks of switches like this are not
uncommon in homes. There is no obvious mapping between the switches and the
lights being controlled. I once had a similar panel in my home, although with only
six switches. Even after years of living in the house, I could never remember which to
use, so I simply put all the switches either up (on) or down (off). How did I solve the
problem? See Figure 4.5.


**136** _The Design of Everyday Things_


I once lived in a wonderful house on the cliffs of Del Mar, California, designed for us by two young, award-winning architects.
The house was wonderful, and the architects proved their worth
by the spectacular placement of the house and the broad windows
that overlooked the ocean. But they liked spare, neat, modern design
to a fault. Inside the house were, among other things, neat rows of
light switches: A horizontal row of four identical switches in the
front hall, a vertical column of six identical switches in the living
room. “You will get used to it,” the architects assured us when
we complained. We never did. Figure 4.4 shows an eight-switch
bank that I found in a home I was visiting. Who could remember
what each does? My home only had six switches, and that was bad
enough. (Photographs of the switch plate from my Del Mar home
are no longer available.)
The lack of clear communication among the people and organizations constructing parts of a system is perhaps the most common
cause of complicated, confusing designs. A usable design starts
with careful observations of how the tasks being supported are
actually performed, followed by a design process that results in a
good fit to the actual ways the tasks get performed. The technical
name for this method is _task analysis._ The name for the entire process is _human-centered design_ (HCD), discussed in Chapter 6.
The solutions to the problem posed by my Del Mar home require
the natural mappings described in Chapter 3. With six light switches
mounted in a one-dimensional array, vertically on the wall, there is
no way they can map naturally to the two-dimensional, horizontal
placement of the lights in the ceiling. Why place the switches flat
against the wall? Why not redo things? Why not place the switches
horizontally, in exact analogy to the things being controlled, with
a two-dimensional layout so that the switches can be placed on a
floor plan of the building in exact correspondence to the areas that
they control? Match the layout of the lights with the layout of the
switches: the principle of natural mapping. You can see the result
in Figure 4.5. We mounted a floor plan of the living room on a plate
and oriented it to match the room. Switches were placed on the
floor plan so that each switch was located in the area controlled


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **137**


**FIGURE 4.5.** **A Natural Mapping of Light**
**Switches to Lights.** This is how I mapped
five switches to the lights in my living
room. I placed small toggle switches that
fit onto a plan of the home’s living room,
balcony, and hall, with each switch placed
where the light was located. The X by the
center switch indicates where this panel
was located. The surface was tilted to make

it easier to relate it to the horizontal arrangement of the lights, and the slope provided a natural anti-affordance, preventing
people from putting coffee cups and drink
containers on the controls.


by that switch. The plate was mounted with a slight tilt from the
horizontal to make it easy to see and to make the mapping clear:
had the plate been vertical, the mapping would still be ambiguous.
The plate was tilted rather than horizontal to discourage people
(us or visitors) from placing objects, such as cups, on the plate: an
example of an anti-affordance. (We further simplified operations
by moving the sixth switch to a different location where its meaning was clear and it did not confuse, because it stood alone.)
It is unnecessarily difficult to implement this spatial mapping
of switches to lights: the required parts are not available. I had to
hire a skilled technician to construct the wall-mounted box and

install the special switches and control equipment. Builders and
electricians need standardized components. Today, the switch
boxes that are available to electricians are organized as rectangular boxes meant to hold a long, linear string of switches and to
be mounted horizontally or vertically on the wall. To produce the
appropriate spatial array, we would need a two-dimensional structure that could be mounted parallel to the floor, where the switches
would be mounted on the top of the box, on the horizontal surface.
The switch box should have a matrix of supports so that there can
be free, relatively unrestricted placement of the switches in whatever pattern best suits the room. Ideally the box would use small
switches, perhaps low-voltage switches that would control a separately mounted control structure that takes care of the lights (which
is what I did in my home). Switches and lights could communicate


**138** _The Design of Everyday Things_


wirelessly instead of through the traditional home wiring cables.
Instead of the standardized light plates for today’s large, bulky
switches, the plates should be designed for small holes appropriate to the small switches, combined with a way of inserting a floor
plan on to the switch cover.
My suggestion requires that the switch box stick out from the
wall, whereas today’s boxes are mounted so that the switches are
flush with the wall. But these new switch boxes wouldn’t have to

stick out. They could be placed in indented openings in the walls:
just as there is room inside the wall for the existing switch boxes,
there is also room for an indented horizontal surface. Or the

switches could be mounted on a little pedestal.
As a side note, in the decades that have passed since the first edition of this book was published, the section on natural mappings
and the difficulties with light switches has received a very popular
reception. Nonetheless, there are no commercial tools available
to make it easy to implement these ideas in the home. I once tried
to convince the CEO of the company whose smart home devices I
had used to implement the controls of Figure 4.5, to use the idea.
“Why not manufacture the components to make it easy for people
to do this,” I suggested. I failed.
Someday, we will get rid of the hard-wired switches, which require excessive runs of electrical cable, add to the cost and difficulties of home construction, and make remodeling of electrical
circuits extremely difficult and time consuming. Instead, we will
use Internet or wireless signals to connect switches to the devices
to be controlled. In this way, controls could be located anywhere.
They could be reconfigured or moved. We could have multiple controls for the same item, some in our phones or other portable devices. I can control my home thermostat from anywhere in the
world: why can’t I do the same with my lights? Some of the necessary technology does exist today in specialty shops and custom
builders, but they will not come into widespread usage until major manufacturers make the necessary components and traditional
electricians become comfortable with installing them. The tools for
creating switch configurations that use good mapping principles


four: _Knowing What to Do: Constraints, Discoverability, and Feedback_ **139**


could become standard and easy to apply. It will happen, but it
may take considerable time.
Alas, like many things that change, new technologies will
bring virtues and deficits. The controls are apt to be through
touch-sensitive screens, allowing excellent natural mapping to the
spatial layouts involved, but lacking the physical affordances of
physical switches. They can’t be operated with the side of the arm
or the elbow while trying to enter a room, hands loaded with packages or cups of coffee. Touch screens are fine if the hands are free.
Perhaps cameras that recognize gestures will do the job.


**ACTIVITY-CENTERED CONTROLS**


Spatial mapping of switches is not always appropriate. In many
cases it is better to have switches that control activities: activitycentered control. Many auditoriums in schools and companies
have computer-based controls, with switches labeled with such
phrases as “video,” “computer,” “full lights,” and “lecture.” When
carefully designed, with a good, detailed analysis of the activities to be supported, the mapping of controls to activities works
extremely well: video requires a dark auditorium plus control of
sound level and controls to start, pause, and stop the presentation.
Projected images require a dark screen area with enough light in
the auditorium so people can take notes. Lectures require some
stage lights so the speaker can be seen. Activity-based controls are
excellent in theory, but the practice is difficult to get right. When it
is done badly, it creates difficulties.
A related but wrong approach is to be device-centered rather
than activity-centered. When they are device-centered, different
control screens cover lights, sound, computer, and video projection. This requires the lecturer to go to one screen to adjust the
light, a different screen to adjust sound levels, and yet a different
screen to advance or control the images. It is a horrible cognitive
interruption to the flow of the talk to go back and forth among the
screens, perhaps to pause the video in order to make a comment
or answer a question. Activity-centered controls anticipate this need
and put light, sound level, and projection controls all in one location.


**140** _The Design of Everyday Things_


I once used an activity-centered control, setting it to present my
photographs to the audience. All worked well until I was asked a
question. I paused to answer it, but wanted to raise the room lights
so I could see the audience. No, the activity of giving a talk with
visually presented images meant that room lights were fixed at a
dim setting. When I tried to increase the light intensity, this took
me out of “giving a talk” activity, so I did get the light to where I
wanted it, but the projection screen also went up into the ceiling
and the projector was turned off. The difficulty with activity-based
controllers is handling the exceptional cases, the ones not thought
about during design.
Activity-centered controls are the proper way to go, if the activities are carefully selected to match actual requirements. But
even in these cases, manual controls will still be required because
there will always be some new, unexpected demand that requires
idiosyncratic settings. As my example demonstrates, invoking
the manual settings should not cause the current activity to be
canceled.