---
title: "Standardization and Technology"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 43
scraped_date: '2026-01-19'
---

**Standardization and Technology**


If we examine the history of advances in all technological fields,
we see that some improvements come naturally through the technology itself, others come through standardization. The early history of the automobile is a good example. The first cars were very
difficult to operate. They required strength and skill beyond the
abilities of many. Some problems were solved through automation:
the choke, the spark advance, and the starter engine. Other aspects
of cars and driving were standardized through the long process of
international standards committees:


   - On which side of the road to drive (constant within a country, but
variable across countries)

   - On which side of the car the driver sits (depends upon which side of
the road the car is driven)

   - The location of essential components: steering wheel, brake, clutch,
and accelerator (the same, whether on the left- or right-hand side of
the car)


Standardization is one type of cultural constraint. With standardization, once you have learned to drive one car, you feel justifiably
confident that you can drive any car, anyplace in the world. Standardization provides a major breakthrough in usability.


**ESTABLISHING STANDARDS**


I have enough friends on national and international standards
committees to realize that the process of determining an internationally accepted standard is laborious. Even when all parties
agree on the merits of standardization, the task of selecting standards becomes a lengthy, politicized issue. A small company can
standardize its products without too much difficulty, but it is much
more difficult for an industrial, national, or international body to


**248** _The Design of Everyday Things_


agree to standards. There even
exists a standardized procedure
for establishing national and **10** **8**
international standards. A set **11** **7**
of national and international

organizations works on standards; when a new standard is **1** **5**
proposed, it must work its way
through the organizational hi- **3**
erarchy. Each step is complex,
for if there are three ways of do
**FIGURE 6.4.** **The Nonstandard Clock.**

ing something, then there are What time is it? This clock is just as logsure to be strong proponents ical as the standard one, except the hands

move in the opposite direction and “12” is

of each of the three ways, plus not in its usual place. Same logic, though.
people who will argue that it is So why is it so difficult to read? What time

is being displayed? 7:11, of course.

too early to standardize.
Each proposal is debated at the
standards committee meeting where it is presented, then taken back
to the sponsoring organization—which is sometimes a company,
sometimes a professional society—where objections and counterobjections are collected. Then the standards committee meets again
to discuss the objections. And again and again and again. Any company that is already marketing a product that meets the proposed
standard will have a huge economic advantage, and the debates are
therefore often affected as much by the economics and politics of
the issues as by real technological substance. The process is almost
guaranteed to take five years, and quite often longer.
The resulting standard is usually a compromise among the various competing positions, oftentimes an inferior compromise.
Sometimes the answer is to agree on several incompatible standards. Witness the existence of both metric and English units; of
left-hand- and right-hand-drive automobiles. There are several international standards for the voltages and frequencies of electricity,
and several different kinds of electrical plugs and sockets—which
cannot be interchanged.























**FIGURE 6.4.** **The Nonstandard Clock.**
What time is it? This clock is just as logical as the standard one, except the hands
move in the opposite direction and “12” is
not in its usual place. Same logic, though.
So why is it so difficult to read? What time
is being displayed? 7:11, of course.



six: _Design Thinking_ **249**


**WHY STANDARDS ARE NECESSARY:**

**A SIMPLE ILLUSTRATION**


With all these difficulties and with the continual advances in tech
nology, are standards really necessary? Yes, they are. Take the everyday clock. It’s standardized. Consider how much trouble you
would have telling time with a backward clock, where the hands
revolved “counterclockwise.” A few such clocks exist, primarily as
humorous conversation pieces. When a clock truly violates standards, such as the one in Figure 6.4 on the previous page, it is difficult to determine what time is being displayed. Why? The logic
behind the time display is identical to that of conventional clocks:
there are only two differences—the hands rotate in the opposite
direction (counterclockwise) and the location of “12,” usually at
the top, has been moved. This clock is just as logical as the standard one. It bothers us because we have standardized on a differ
ent scheme, on the very definition of the term _clockwise._ Without
such standardization, clock reading would be more difficult: you’d
always have to figure out the mapping.


**A STANDARD THAT TOOK SO LONG,**

**TECHNOLOGY OVERRAN IT**


I myself participated at the very end of the incredibly long,
complex political process of establishing the US standards for
high-definition television. In the 1970s, the Japanese developed a
national television system that had much higher resolution than the
standards then in use: they called it “high-definition television.”
In 1995, two decades later, the television industry in the United
States proposed its own high-definition TV standard (HDTV) to the
Federal Communications Commission (FCC). But the computer industry pointed out that the proposals were not compatible with the
way that computers displayed images, so the FCC objected to the
proposed standards. Apple mobilized other members of the industry and, as vice president of advanced technology, I was selected
to be the spokesperson for Apple. (In the following description,
ignore the jargon—it doesn’t matter.) The TV industry proposed a


**250** _The Design of Everyday Things_


wide variety of permissible formats, including ones with rectangular pixels and interlaced scan. Because of the technical limitations
in the 1990s, it was suggested that the highest-quality picture have
1,080 interlaced lines (1080i). We wanted only progressive scan, so
we insisted upon 720 lines, progressively displayed (720p), arguing that the progressive nature of the scan made up for the lesser
number of lines.

The battle was heated. The FCC told all the competing parties
to lock themselves into a room and not to come out until they had
reached agreement. As a result, I spent many hours in lawyers’
offices. We ended up with a crazy agreement that recognized multiple variations of the standard, with resolutions of 480i and 480p
(called _standard definition_ ), 720p and 1080i (called _high-definition_ ),
and two different aspect ratios for the screens (the ratio of width to
height), 4:3 (= 1.3)—the old standard—and 16:9 (= 1.8)—the new
standard. In addition, a large number of frame rates were supported (basically, how many times per second the image was transmitted). Yes, it was a standard, or more accurately a large number
of standards. In fact, one of the allowed methods of transmission
was to use any method (as long as it carried its own specifications
along with the signal). It was a mess, but we did reach agreement.
After the standard was made official in 1996, it took roughly ten
more years for HDTV to become accepted, helped, finally, by a
new generation of television displays that were large, thin, and inexpensive. The whole process took roughly thirty-five years from
the first broadcasts by the Japanese.
Was it worth the fight? Yes and no. In the thirty-five years that it
took to reach the standard, the technology continued to evolve, so
the resulting standard was far superior to the first one proposed
so many years before. Moreover, the HDTV of today is a huge improvement over what we had before (now called “standard definition”). But the minutiae of details that were the focus of the fight
between the computer and TV companies was silly. My technical
experts continually tried to demonstrate to me the superiority of
720p images over 1080i, but it took me hours of viewing special


six: _Design Thinking_ **251**


scenes under expert guidance to see the deficiencies of the interlaced images (the differences only show up with complex moving
images). So why did we care?
Television displays and compression techniques have improved
so much that interlacing is no longer needed. Images at 1080p,
once thought to be impossible, are now commonplace. Sophisticated algorithms and high-speed processors make it possible to
transform one standard into another; even rectangular pixels are
no longer a problem.
As I write these words, the main problem is the discrepancy in
aspect ratios. Movies come in many different aspect ratios (none
of them the new standard) so when TV screens show movies, they
either have to cut off part of the image or leave parts of the screen
black. Why was the HDTV aspect ratio set at 16:9 (or 1.8) if no
movies used that ratio? Because engineers liked it: square the old
aspect ratio of 4:3 and you get the new one, 16:9.
Today we are about to embark on yet another standards fight
over TV. First, there is three-dimensional TV: 3-D. Then there are
proposals for ultra-high definition: 2,160 lines (and a doubling of
the horizontal resolution as well): four times the resolution of our
best TV today (1080p). One company wants eight times the resolution, and one is proposing an aspect ratio of 21:9 (= 2.3). I have seen
these images and they are marvelous, although they only matter
with large screens (at least 60 inches, or 1.5 meters, in diagonal
length), and when the viewer is close to the display.
Standards can take so long to be established that by the time they
do come into wide practice, they can be irrelevant. Nonetheless,
standards are necessary. They simplify our lives and make it possible for different brands of equipment to work together in harmony.


**A STANDARD THAT NEVER**

**CAUGHT ON: DIGITAL TIME**


Standardize and you simplify lives: everyone learns the system
only once. But don’t standardize too soon; you may be locked into
a primitive technology, or you may have introduced rules that turn
out to be grossly inefficient, even error-inducing. Standardize too


**252** _The Design of Everyday Things_


late, and there may already be so many ways of doing things that
no international standard can be agreed on. If there is agreement
on an old-fashioned technology, it may be too expensive for everyone to change to the new standard. The metric system is a good example: it is a far simpler and more usable scheme for representing
distance, weight, volume, and temperature than the older English
system of feet, pounds, seconds, and degrees on the Fahrenheit
scale. But industrial nations with a heavy commitment to the old
measurement standard claim they cannot afford the massive costs
and confusion of conversion. So we are stuck with two standards,

at least for a few more decades.

Would you consider changing how we specify time? The current system is arbitrary. The day is divided into twenty-four rather
arbitrary but standard units—hours. But we tell time in units of
twelve, not twenty-four, so there have to be two cycles of twelve
hours each, plus the special convention of a.m. and p.m. so we
know which cycle we are talking about. Then we divide each hour
into sixty minutes and each minute into sixty seconds.
What if we switched to metric divisions: seconds divided into

tenths, milliseconds, and microseconds? We would have days, millidays, and microdays. There would have to be a new hour, minute, and second: call them the digital hour, the digital minute, and
the digital second. It would be easy: ten digital hours to the day,
one hundred digital minutes to the digital hour, one hundred digital seconds to the digital minute.
Each digital hour would last exactly 2.4 times an old hour: 144
old minutes. So the old one-hour period of the schoolroom or
television program would be replaced with a half-digital hour
period, or 50 digital minutes—only 20 percent longer than the
current hour. We could adapt to the differences in durations with
relative ease.

What do I think of it? I much prefer it. After all, the decimal system, the basis of most of the world’s use of numbers and arithmetic, uses base 10 arithmetic and, as a result, arithmetic operations
are much simpler in the metric system. Many societies have used
other systems, 12 and 60 being common. Hence twelve for the


six: _Design Thinking_ **253**


number of items in a dozen, inches in a foot, hours in a day, and
months in a year; sixty for the number of seconds in a minute, seconds in a degree, and minutes in an hour.
The French proposed that time be made into a decimal system
in 1792, during the French Revolution, when the major shift to the
metric system took place. The metric system for weights and lengths
took hold, but not for time. Decimal time was used long enough for
decimal clocks to be manufactured, but it eventually was discarded.
Too bad. It is very difficult to change well-established habits. We
still use the QWERTY keyboard, and the United States still measures
things in inches and feet, yards and miles, Fahrenheit, ounces, and
pounds. The world still measures time in units of 12 and 60, and
divides the circle into 360 degrees.
In 1998, Swatch, the Swiss watch company, made its own attempt
to introduce decimal time through what it called “Swatch International Time.” Swatch divided the day into 1,000 “.beats,” each
.beat being slightly less than 90 seconds (each .beat corresponds to
one digital minute). This system did not use time zones, so people
the world over would be in synchrony with their watches. This
does not simplify the problem of synchronizing scheduled conversations, however, because it would be difficult to get the sun
to behave properly. People would still wish to wake up around
sunrise, and this would occur at different Swatch times around the
world. As a result, even though people would have their watches
synchronized, it would still be necessary to know when they woke
up, ate, went to and from work, and went to sleep, and these times
would vary around the world. It isn’t clear whether Swatch was
serious with its proposal or whether it was one huge advertising
stunt. After a few years of publicity, during which the company
manufactured digital watches that told the time in .beats, it all fizzled away.
Speaking of standardization, Swatch called its basic time unit a
“.beat” with the first character being a period. This nonstandard
spelling wreaks havoc on spelling correction systems that aren’t set
up to handle words that begin with punctuation marks.


**254** _The Design of Everyday Things_