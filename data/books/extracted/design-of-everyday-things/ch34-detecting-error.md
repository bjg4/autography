---
title: "Detecting Error"
author: Don Norman
source_type: book_chapter
book_title: "The Design of Everyday Things"
chapter_number: 34
scraped_date: '2026-01-19'
---

**Detecting Error**


Errors do not necessarily lead to harm if they are discovered
quickly. The different categories of errors have differing ease of
discovery. In general, action slips are relatively easy to discover;
mistakes, much more difficult. Action slips are relatively easy to
detect because it is usually easy to notice a discrepancy between
the intended act and the one that got performed. But this detection
can only take place if there is feedback. If the result of the action is
not visible, how can the error be detected?


**194** _The Design of Everyday Things_


Memory-lapse slips are difficult to detect precisely because there
is nothing to see. With a memory slip, the required action is not
performed. When no action is done, there is nothing to detect. It is
only when the lack of action allows some unwanted event to occur
that there is hope of detecting a memory-lapse slip.
Mistakes are difficult to detect because there is seldom anything
that can signal an inappropriate goal. And once the wrong goal or
plan is decided upon, the resulting actions are consistent with that
wrong goal, so careful monitoring of the actions not only fails to detect the erroneous goal, but, because the actions are done correctly,
can inappropriately provide added confidence to the decision.
Faulty diagnoses of a situation can be surprisingly difficult to
detect. You might expect that if the diagnosis was wrong, the actions would turn out to be ineffective, so the fault would be discovered quickly. But misdiagnoses are not random. Usually they are
based on considerable knowledge and logic. The misdiagnosis is
usually both reasonable and relevant to eliminating the symptoms
being observed. As a result, the initial actions are apt to appear appropriate and helpful. This makes the problem of discovery even
more difficult. The actual error might not be discovered for hours
or days.
Memory-lapse mistakes are especially difficult to detect. Just as
with a memory-lapse slip the absence of something that should
have been done is always more difficult to detect than the presence
of something that should not have been done. The difference between memory-lapse slips and mistakes is that, in the first case, a
single component of a plan is skipped, whereas in the second, the
entire plan is forgotten. Which is easier to discover? At this point
I must retreat to the standard answer science likes to give to questions of this sort: “It all depends.”


**EXPLAINING AWAY MISTAKES**


Mistakes can take a long time to be discovered. Hear a noise that
sounds like a pistol shot and think: “Must be a car’s exhaust backfiring.” Hear someone yell outside and think: “Why can’t my


five: _Human Error? No, Bad Design_ **195**


neighbors be quiet?” Are we correct in dismissing these incidents?
Most of the time we are, but when we’re not, our explanations can
be difficult to justify.
Explaining away errors is a common problem in commercial
accidents. Most major accidents are preceded by warning signs:
equipment malfunctions or unusual events. Often, there is a series
of apparently unrelated breakdowns and errors that culminate in
major disaster. Why didn’t anyone notice? Because no single incident appeared to be serious. Often, the people involved noted
each problem but discounted it, finding a logical explanation for
the otherwise deviant observation.


**T HE CASE OF T HE W RONG T U R N ON A HIGH WAY**


I’ve misinterpreted highway signs, as I’m sure most drivers have.
My family was traveling from San Diego to Mammoth Lakes, California, a ski area about 400 miles north. As we drove, we noticed
more and more signs advertising the hotels and gambling casinos
of Las Vegas, Nevada. “Strange,” we said, “Las Vegas always did
advertise a long way off—there is even a billboard in San Diego—
but this seems excessive, advertising on the road to Mammoth.”
We stopped for gasoline and continued on our journey. Only later,
when we tried to find a place to eat supper, did we discover that we
had missed a turn nearly two hours earlier, before we had stopped
for gasoline, and that we were actually on the road to Las Vegas,
not the road to Mammoth. We had to backtrack the entire two
hour segment, wasting four hours of driving. It’s humorous now;
it wasn’t then.

Once people find an explanation for an apparent anomaly, they
tend to believe they can now discount it. But explanations are
based on analogy with past experiences, experiences that may not
apply to the current situation. In the driving story, the prevalence
of billboards for Las Vegas was a signal we should have heeded,
but it seemed easily explained. Our experience is typical: some
major industrial incidents have resulted from false explanations of
anomalous events. But do note: usually these apparent anomalies
should be ignored. Most of the time, the explanation for their pres

**196** _The Design of Everyday Things_


ence is correct. Distinguishing a true anomaly from an apparent
one is difficult.


**IN HINDSIGHT, EVENTS SEEM LOGICAL**


The contrast in our understanding before and after an event can be
dramatic. The psychologist Baruch Fischhoff has studied explanations given in hindsight, where events seem completely obvious and
predictable after the fact but completely unpredictable beforehand.
Fischhoff presented people with a number of situations and
asked them to predict what would happen: they were correct only
at the chance level. When the actual outcome was not known by the
people being studied, few predicted the actual outcome. He then
presented the same situations along with the actual outcomes to
another group of people, asking them to state how likely each outcome was: when the actual outcome was known, it appeared to be
plausible and likely and other outcomes appeared unlikely.
Hindsight makes events seem obvious and predictable. Foresight
is difficult. During an incident, there are never clear clues. Many
things are happening at once: workload is high, emotions and
stress levels are high. Many things that are happening will turn
out to be irrelevant. Things that appear irrelevant will turn out
to be critical. The accident investigators, working with hindsight,
knowing what really happened, will focus on the relevant information and ignore the irrelevant. But at the time the events were
happening, the operators did not have information that allowed
them to distinguish one from the other.
This is why the best accident analyses can take a long time to
do. The investigators have to imagine themselves in the shoes of
the people who were involved and consider all the information,
all the training, and what the history of similar past events would
have taught the operators. So, the next time a major accident occurs, ignore the initial reports from journalists, politicians, and
executives who don’t have any substantive information but feel
compelled to provide statements anyway. Wait until the official
reports come from trusted sources. Unfortunately, this could be
months or years after the accident, and the public usually wants


five: _Human Error? No, Bad Design_ **197**


answers immediately, even if those answers are wrong. Moreover,
when the full story finally appears, newspapers will no longer consider it news, so they won’t report it. You will have to search for
the official report. In the United States, the National Transportation
Safety Board (NTSB) can be trusted. NTSB conducts careful investigations of all major aviation, automobile and truck, train, ship,
and pipeline incidents. (Pipelines? Sure: pipelines transport coal,
gas, and oil.)